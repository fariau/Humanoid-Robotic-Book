"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[754],{7487:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>_,frontMatter:()=>o,metadata:()=>c,toc:()=>d});var i=t(4848),s=t(8453),a=t(8931);const o={sidebar_position:11,title:"Safety & Ethics in Robotics",description:"Exploring safety protocols, ethical considerations, and responsible development practices in humanoid robotics and AI systems.",keywords:["robotics safety","AI ethics","robot ethics","safety protocols","responsible AI","human-robot interaction safety"]},r="Chapter 11: Safety & Ethics in Robotics",c={id:"safety-ethics/index",title:"Safety & Ethics in Robotics",description:"Exploring safety protocols, ethical considerations, and responsible development practices in humanoid robotics and AI systems.",source:"@site/docs/safety-ethics/index.mdx",sourceDirName:"safety-ethics",slug:"/safety-ethics/",permalink:"/Humanoid-Robotic-Book/docs/safety-ethics/",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/safety-ethics/index.mdx",tags:[],version:"current",sidebarPosition:11,frontMatter:{sidebar_position:11,title:"Safety & Ethics in Robotics",description:"Exploring safety protocols, ethical considerations, and responsible development practices in humanoid robotics and AI systems.",keywords:["robotics safety","AI ethics","robot ethics","safety protocols","responsible AI","human-robot interaction safety"]},sidebar:"tutorialSidebar",previous:{title:"Learning & Adaptation",permalink:"/Humanoid-Robotic-Book/docs/learning-adaptation/"},next:{title:"Deployment & Optimization",permalink:"/Humanoid-Robotic-Book/docs/deployment-optimization/"}},l={},d=[{value:"Introduction",id:"introduction",level:2},{value:"Safety Protocols and Standards",id:"safety-protocols-and-standards",level:2},{value:"International Safety Standards",id:"international-safety-standards",level:3},{value:"Risk Assessment Frameworks",id:"risk-assessment-frameworks",level:3},{value:"Safety Architecture Design",id:"safety-architecture-design",level:3},{value:"Ethical Frameworks in Robotics",id:"ethical-frameworks-in-robotics",level:2},{value:"Asimov&#39;s Laws of Robotics",id:"asimovs-laws-of-robotics",level:3},{value:"Modern Ethical Frameworks",id:"modern-ethical-frameworks",level:3},{value:"Privacy and Data Protection",id:"privacy-and-data-protection",level:2},{value:"Data Minimization and Consent",id:"data-minimization-and-consent",level:3},{value:"Human-Robot Interaction Safety",id:"human-robot-interaction-safety",level:2},{value:"Physical Safety in HRI",id:"physical-safety-in-hri",level:3},{value:"Ethical AI Development Practices",id:"ethical-ai-development-practices",level:2},{value:"Fairness and Bias Mitigation",id:"fairness-and-bias-mitigation",level:3},{value:"Hardware-Specific Safety Implementations",id:"hardware-specific-safety-implementations",level:2},{value:"GPU-Accelerated Safety Systems",id:"gpu-accelerated-safety-systems",level:3},{value:"Jetson-Based Safety Systems",id:"jetson-based-safety-systems",level:3},{value:"Real Robot Safety Integration",id:"real-robot-safety-integration",level:3},{value:"Urdu Content: \u0633\u06cc\u0641\u0679\u06cc \u0627\u0648\u0631 \u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a",id:"urdu-content-\u0633\u06cc\u0641\u0679\u06cc-\u0627\u0648\u0631-\u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a",level:2},{value:"\u062a\u0639\u0627\u0631\u0641",id:"\u062a\u0639\u0627\u0631\u0641",level:2},{value:"\u0633\u06cc\u0641\u0679\u06cc \u067e\u0631\u0648\u0679\u0648\u06a9\u0648\u0644\u0632 \u0627\u0648\u0631 \u0645\u0639\u06cc\u0627\u0631\u0627\u062a",id:"\u0633\u06cc\u0641\u0679\u06cc-\u067e\u0631\u0648\u0679\u0648\u06a9\u0648\u0644\u0632-\u0627\u0648\u0631-\u0645\u0639\u06cc\u0627\u0631\u0627\u062a",level:2},{value:"\u0628\u06cc\u0646 \u0627\u0644\u0627\u0642\u0648\u0627\u0645\u06cc \u0633\u06cc\u0641\u0679\u06cc \u0645\u0639\u06cc\u0627\u0631\u0627\u062a",id:"\u0628\u06cc\u0646-\u0627\u0644\u0627\u0642\u0648\u0627\u0645\u06cc-\u0633\u06cc\u0641\u0679\u06cc-\u0645\u0639\u06cc\u0627\u0631\u0627\u062a",level:3},{value:"\u0631\u0633\u06a9 \u062c\u0627\u0626\u0632\u06c1 \u06a9\u06d2 \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9\u0633",id:"\u0631\u0633\u06a9-\u062c\u0627\u0626\u0632\u06c1-\u06a9\u06d2-\u0641\u0631\u06cc\u0645-\u0648\u0631\u06a9\u0633",level:3},{value:"\u0633\u06cc\u0641\u0679\u06cc \u0622\u0631\u06a9\u06cc\u0679\u06cc\u06a9\u0686\u0631 \u0688\u06cc\u0632\u0627\u0626\u0646",id:"\u0633\u06cc\u0641\u0679\u06cc-\u0622\u0631\u06a9\u06cc\u0679\u06cc\u06a9\u0686\u0631-\u0688\u06cc\u0632\u0627\u0626\u0646",level:3},{value:"\u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0645\u06cc\u06ba \u0627\u062e\u0644\u0627\u0642\u06cc \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9\u0633",id:"\u0631\u0648\u0628\u0648\u0679\u06a9\u0633-\u0645\u06cc\u06ba-\u0627\u062e\u0644\u0627\u0642\u06cc-\u0641\u0631\u06cc\u0645-\u0648\u0631\u06a9\u0633",level:2},{value:"\u0627\u06cc\u0632\u06cc\u0645\u0648\u0648 \u06a9\u06d2 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u06a9\u06d2 \u0642\u0648\u0627\u0646\u06cc\u0646",id:"\u0627\u06cc\u0632\u06cc\u0645\u0648\u0648-\u06a9\u06d2-\u0631\u0648\u0628\u0648\u0679\u06a9\u0633-\u06a9\u06d2-\u0642\u0648\u0627\u0646\u06cc\u0646",level:3},{value:"\u062c\u062f\u06cc\u062f \u0627\u062e\u0644\u0627\u0642\u06cc \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9\u0633",id:"\u062c\u062f\u06cc\u062f-\u0627\u062e\u0644\u0627\u0642\u06cc-\u0641\u0631\u06cc\u0645-\u0648\u0631\u06a9\u0633",level:3},{value:"\u0631\u0627\u0632\u062f\u0627\u0631\u06cc \u0627\u0648\u0631 \u0688\u06cc\u0679\u0627 \u06a9\u06cc \u062d\u0641\u0627\u0638\u062a",id:"\u0631\u0627\u0632\u062f\u0627\u0631\u06cc-\u0627\u0648\u0631-\u0688\u06cc\u0679\u0627-\u06a9\u06cc-\u062d\u0641\u0627\u0638\u062a",level:2},{value:"\u0688\u06cc\u0679\u0627 \u06a9\u0645\u06cc \u0627\u0648\u0631 \u0631\u0636\u0627\u0645\u0646\u062f\u06cc",id:"\u0688\u06cc\u0679\u0627-\u06a9\u0645\u06cc-\u0627\u0648\u0631-\u0631\u0636\u0627\u0645\u0646\u062f\u06cc",level:3},{value:"\u0627\u0646\u0633\u0627\u0646-\u0631\u0648\u0628\u0648\u0679 \u0628\u0627\u062a \u0686\u06cc\u062a \u06a9\u06cc \u0633\u06cc\u0641\u0679\u06cc",id:"\u0627\u0646\u0633\u0627\u0646-\u0631\u0648\u0628\u0648\u0679-\u0628\u0627\u062a-\u0686\u06cc\u062a-\u06a9\u06cc-\u0633\u06cc\u0641\u0679\u06cc",level:2},{value:"\u0627\u06cc\u0686 \u0622\u0631 \u0622\u0626\u06cc \u0645\u06cc\u06ba \u062c\u0633\u0645\u0627\u0646\u06cc \u0633\u06cc\u0641\u0679\u06cc",id:"\u0627\u06cc\u0686-\u0622\u0631-\u0622\u0626\u06cc-\u0645\u06cc\u06ba-\u062c\u0633\u0645\u0627\u0646\u06cc-\u0633\u06cc\u0641\u0679\u06cc",level:3},{value:"\u0627\u062e\u0644\u0627\u0642\u06cc AI \u062a\u0631\u0642\u06cc \u06a9\u06cc \u0645\u0634\u0642\u06cc\u06ba",id:"\u0627\u062e\u0644\u0627\u0642\u06cc-ai-\u062a\u0631\u0642\u06cc-\u06a9\u06cc-\u0645\u0634\u0642\u06cc\u06ba",level:2},{value:"\u0627\u0646\u0635\u0627\u0641 \u0627\u0648\u0631 \u062a\u0648\u0627\u0632\u0646 \u06a9\u0645\u06cc",id:"\u0627\u0646\u0635\u0627\u0641-\u0627\u0648\u0631-\u062a\u0648\u0627\u0632\u0646-\u06a9\u0645\u06cc",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Practice Exercises",id:"practice-exercises",level:2},{value:"Quiz: Safety &amp; Ethics in Robotics",id:"quiz-safety--ethics-in-robotics",level:2},{value:"Further Reading",id:"further-reading",level:2}];function f(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,s.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(a.n,{}),"\n",(0,i.jsx)(a.B,{}),"\n",(0,i.jsx)(n.h1,{id:"chapter-11-safety--ethics-in-robotics",children:"Chapter 11: Safety & Ethics in Robotics"}),"\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(n.p,{children:"Welcome to Chapter 11 of the Physical AI & Humanoid Robotics textbook. This chapter addresses one of the most critical aspects of robotics development: safety and ethics. As humanoid robots become more sophisticated and integrated into human environments, ensuring their safe operation and ethical behavior becomes paramount."}),"\n",(0,i.jsx)(n.p,{children:"This chapter explores the multifaceted challenges of developing safe and ethical robotic systems. We'll examine safety protocols, ethical frameworks, risk assessment methodologies, and responsible development practices that ensure humanoid robots can operate safely alongside humans while respecting ethical principles and societal values."}),"\n",(0,i.jsx)(n.p,{children:"The importance of safety and ethics in robotics cannot be overstated. As these systems become more autonomous and capable, the potential consequences of failures or unethical behavior increase exponentially. This chapter provides a comprehensive framework for addressing these challenges in the development of humanoid robots."}),"\n",(0,i.jsx)(n.h2,{id:"safety-protocols-and-standards",children:"Safety Protocols and Standards"}),"\n",(0,i.jsx)(n.p,{children:"Safety in robotics encompasses both physical safety (preventing harm to humans and the environment) and operational safety (ensuring reliable and predictable robot behavior). The development of comprehensive safety protocols is essential for the deployment of humanoid robots in real-world environments."}),"\n",(0,i.jsx)(n.h3,{id:"international-safety-standards",children:"International Safety Standards"}),"\n",(0,i.jsx)(n.p,{children:"The robotics industry has established several key safety standards that guide the design and operation of robotic systems:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ISO 13482"}),": Safety requirements for personal care robots"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ISO 12100"}),": Safety of machinery principles for risk assessment"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ISO 10218"}),": Safety requirements for industrial robots"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ANSI/RIA R15.06"}),": American National Standard for industrial robots and robot systems"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    A[Safety Standards in Robotics] --\x3e B[ISO 13482 - Personal Care Robots]\n    A --\x3e C[ISO 12100 - Risk Assessment]\n    A --\x3e D[ISO 10218 - Industrial Robots]\n    A --\x3e E[ANSI/RIA R15.06 - Industrial Standards]\n\n    B --\x3e B1[Human Interaction Safety]\n    B --\x3e B2[Privacy Protection]\n    B --\x3e B3[Ergonomic Design]\n\n    C --\x3e C1[Risk Identification]\n    C --\x3e C2[Risk Evaluation]\n    C --\x3e C3[Risk Reduction]\n\n    D --\x3e D1[Physical Safety]\n    D --\x3e D2[Emergency Stops]\n    D --\x3e D3[Safe Movement]\n\n    E --\x3e E1[Operator Safety]\n    E --\x3e E2[Environmental Safety]\n    E --\x3e E3[System Safety]\n"})}),"\n",(0,i.jsx)(n.h3,{id:"risk-assessment-frameworks",children:"Risk Assessment Frameworks"}),"\n",(0,i.jsx)(n.p,{children:"Effective safety protocols begin with comprehensive risk assessment. This involves identifying potential hazards, evaluating their likelihood and severity, and implementing appropriate mitigation strategies."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Example: Risk Assessment Framework for Robotic Systems\nimport numpy as np\nfrom enum import Enum\n\nclass RiskLevel(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\nclass RiskAssessment:\n    def __init__(self):\n        self.hazards = []\n        self.risk_matrix = np.zeros((4, 4))  # Severity x Probability\n\n    def add_hazard(self, hazard_id, description, severity, probability):\n        """\n        Add a hazard to the risk assessment\n        severity: 1-5 scale (5 = most severe)\n        probability: 1-5 scale (5 = most likely)\n        """\n        risk_score = severity * probability\n\n        if risk_score <= 4:\n            risk_level = RiskLevel.LOW\n        elif risk_score <= 8:\n            risk_level = RiskLevel.MEDIUM\n        elif risk_score <= 15:\n            risk_level = RiskLevel.HIGH\n        else:\n            risk_level = RiskLevel.CRITICAL\n\n        hazard = {\n            \'id\': hazard_id,\n            \'description\': description,\n            \'severity\': severity,\n            \'probability\': probability,\n            \'risk_score\': risk_score,\n            \'risk_level\': risk_level,\n            \'mitigation_strategies\': []\n        }\n\n        self.hazards.append(hazard)\n        return hazard\n\n    def evaluate_risk_matrix(self):\n        """\n        Evaluate the risk matrix and identify critical areas\n        """\n        for hazard in self.hazards:\n            severity_idx = hazard[\'severity\'] - 1\n            prob_idx = hazard[\'probability\'] - 1\n            self.risk_matrix[severity_idx][prob_idx] += 1\n\n    def get_mitigation_recommendations(self):\n        """\n        Generate mitigation recommendations based on risk levels\n        """\n        recommendations = {\n            RiskLevel.LOW: ["Monitor regularly", "Basic documentation"],\n            RiskLevel.MEDIUM: ["Implement safety measures", "Regular testing", "User training"],\n            RiskLevel.HIGH: ["Redesign if possible", "Multiple safety layers", "Frequent monitoring"],\n            RiskLevel.CRITICAL: ["Do not proceed", "Fundamental redesign required", "Expert consultation"]\n        }\n\n        return recommendations\n\n# Example usage\ndef assess_robot_safety():\n    assessment = RiskAssessment()\n\n    # Add common robotic hazards\n    assessment.add_hazard(\n        "H001",\n        "Physical collision with humans",\n        severity=5,\n        probability=3\n    )\n\n    assessment.add_hazard(\n        "H002",\n        "System failure during critical operation",\n        severity=4,\n        probability=2\n    )\n\n    assessment.add_hazard(\n        "H003",\n        "Data privacy breach",\n        severity=3,\n        probability=2\n    )\n\n    assessment.evaluate_risk_matrix()\n    return assessment\n'})}),"\n",(0,i.jsx)(n.h3,{id:"safety-architecture-design",children:"Safety Architecture Design"}),"\n",(0,i.jsx)(n.p,{children:"A robust safety architecture incorporates multiple layers of protection to ensure safe robot operation even in the presence of failures or unexpected conditions."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Example: Safety Architecture for Humanoid Robot\nimport threading\nimport time\nfrom dataclasses import dataclass\nfrom typing import List, Optional\n\n@dataclass\nclass SafetyConstraint:\n    name: str\n    min_value: float\n    max_value: float\n    current_value: float\n    enabled: bool = True\n\nclass SafetyMonitor:\n    def __init__(self):\n        self.constraints = []\n        self.emergency_stop = False\n        self.monitoring_thread = None\n        self.is_monitoring = False\n\n    def add_constraint(self, name: str, min_val: float, max_val: float):\n        """Add a safety constraint to monitor"""\n        constraint = SafetyConstraint(name, min_val, max_val, 0.0)\n        self.constraints.append(constraint)\n\n    def update_constraint(self, name: str, value: float):\n        """Update constraint value"""\n        for constraint in self.constraints:\n            if constraint.name == name:\n                constraint.current_value = value\n                break\n\n    def check_constraints(self) -> List[str]:\n        """Check all constraints and return violations"""\n        violations = []\n        for constraint in self.constraints:\n            if constraint.enabled:\n                if constraint.current_value < constraint.min_value or \\\n                   constraint.current_value > constraint.max_value:\n                    violations.append(constraint.name)\n        return violations\n\n    def start_monitoring(self):\n        """Start continuous safety monitoring"""\n        self.is_monitoring = True\n        self.monitoring_thread = threading.Thread(target=self._monitor_loop)\n        self.monitoring_thread.start()\n\n    def stop_monitoring(self):\n        """Stop safety monitoring"""\n        self.is_monitoring = False\n        if self.monitoring_thread:\n            self.monitoring_thread.join()\n\n    def _monitor_loop(self):\n        """Internal monitoring loop"""\n        while self.is_monitoring:\n            violations = self.check_constraints()\n            if violations:\n                print(f"Safety violations detected: {violations}")\n                self.trigger_emergency_stop()\n\n            time.sleep(0.01)  # 100 Hz monitoring\n\n    def trigger_emergency_stop(self):\n        """Trigger emergency stop and log incident"""\n        self.emergency_stop = True\n        print("EMERGENCY STOP ACTIVATED!")\n        # In real implementation, would send stop commands to robot\n\nclass SafetyController:\n    def __init__(self):\n        self.safety_monitor = SafetyMonitor()\n        self.initialize_constraints()\n\n    def initialize_constraints(self):\n        """Initialize all safety constraints"""\n        # Joint position limits\n        for i in range(12):  # Assuming 12 joints\n            self.safety_monitor.add_constraint(\n                f"joint_{i}_position",\n                min_val=-2.5,\n                max_val=2.5\n            )\n\n        # Joint velocity limits\n        for i in range(12):\n            self.safety_monitor.add_constraint(\n                f"joint_{i}_velocity",\n                min_val=-5.0,\n                max_val=5.0\n            )\n\n        # Joint torque limits\n        for i in range(12):\n            self.safety_monitor.add_constraint(\n                f"joint_{i}_torque",\n                min_val=-100.0,\n                max_val=100.0\n            )\n\n        # End-effector position limits (workspace)\n        self.safety_monitor.add_constraint("ee_x_position", -1.0, 1.0)\n        self.safety_monitor.add_constraint("ee_y_position", -1.0, 1.0)\n        self.safety_monitor.add_constraint("ee_z_position", 0.1, 2.0)\n\n    def check_safety(self, joint_positions, joint_velocities, joint_torques, ee_position):\n        """Check safety constraints for given robot state"""\n        # Update constraint values\n        for i, pos in enumerate(joint_positions):\n            self.safety_monitor.update_constraint(f"joint_{i}_position", pos)\n\n        for i, vel in enumerate(joint_velocities):\n            self.safety_monitor.update_constraint(f"joint_{i}_velocity", vel)\n\n        for i, torque in enumerate(joint_torques):\n            self.safety_monitor.update_constraint(f"joint_{i}_torque", torque)\n\n        self.safety_monitor.update_constraint("ee_x_position", ee_position[0])\n        self.safety_monitor.update_constraint("ee_y_position", ee_position[1])\n        self.safety_monitor.update_constraint("ee_z_position", ee_position[2])\n\n        # Check for violations\n        violations = self.safety_monitor.check_constraints()\n        return len(violations) == 0, violations\n\n# Example usage\ndef main():\n    safety_controller = SafetyController()\n    safety_controller.safety_monitor.start_monitoring()\n\n    # Simulate robot state checking\n    joint_positions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n    joint_velocities = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.11, 0.12]\n    joint_torques = [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0]\n    ee_position = [0.5, 0.3, 0.8]\n\n    is_safe, violations = safety_controller.check_safety(\n        joint_positions, joint_velocities, joint_torques, ee_position\n    )\n\n    if is_safe:\n        print("Robot state is safe")\n    else:\n        print(f"Robot state unsafe - violations: {violations}")\n\n    # Cleanup\n    safety_controller.safety_monitor.stop_monitoring()\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"ethical-frameworks-in-robotics",children:"Ethical Frameworks in Robotics"}),"\n",(0,i.jsx)(n.p,{children:"Ethics in robotics addresses the moral principles and values that should guide the design, development, and deployment of robotic systems. As robots become more autonomous and integrated into society, ethical considerations become increasingly important."}),"\n",(0,i.jsx)(n.h3,{id:"asimovs-laws-of-robotics",children:"Asimov's Laws of Robotics"}),"\n",(0,i.jsx)(n.p,{children:"Isaac Asimov's three laws of robotics, while fictional, provide a foundational framework for thinking about robot ethics:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"A robot may not injure a human being or, through inaction, allow a human being to come to harm"}),"\n",(0,i.jsx)(n.li,{children:"A robot must obey the orders given to it by human beings, except where such orders would conflict with the First Law"}),"\n",(0,i.jsx)(n.li,{children:"A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    A[Asimov's Laws of Robotics] --\x3e B[First Law - Human Safety]\n    A --\x3e C[Second Law - Obedience to Humans]\n    A --\x3e D[Third Law - Self-Preservation]\n\n    B --\x3e B1[Prevent Harm to Humans]\n    B --\x3e B2[Prevent Harm Through Inaction]\n\n    C --\x3e C1[Follow Human Orders]\n    C --\x3e C2[Exception: Conflicts with First Law]\n\n    D --\x3e D1[Protect Own Existence]\n    D --\x3e D2[Exception: Conflicts with First or Second Law]\n"})}),"\n",(0,i.jsx)(n.h3,{id:"modern-ethical-frameworks",children:"Modern Ethical Frameworks"}),"\n",(0,i.jsx)(n.p,{children:"Contemporary approaches to robot ethics have evolved beyond Asimov's laws to address the complexities of modern AI and robotics:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Example: Ethical Decision Framework for Robots\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Any\nimport json\n\nclass EthicalPrinciple(Enum):\n    BENEFICENCE = "beneficence"  # Do good\n    NON_MALEFICENCE = "non_maleficence"  # Do no harm\n    AUTONOMY = "autonomy"  # Respect autonomy\n    JUSTICE = "justice"  # Fairness and equality\n    VERACITY = "veracity"  # Truthfulness\n    FIDELITY = "fidelity"  # Loyalty and promise-keeping\n\n@dataclass\nclass EthicalDecision:\n    action: str\n    principle: EthicalPrinciple\n    weight: float  # 0.0 to 1.0\n    justification: str\n\nclass EthicalFramework:\n    def __init__(self):\n        self.principles = {\n            EthicalPrinciple.BENEFICENCE: 1.0,\n            EthicalPrinciple.NON_MALEFICENCE: 1.0,\n            EthicalPrinciple.AUTONOMY: 0.8,\n            EthicalPrinciple.JUSTICE: 0.9,\n            EthicalPrinciple.VERACITY: 0.7,\n            EthicalPrinciple.FIDELITY: 0.6\n        }\n\n        self.decision_log = []\n\n    def evaluate_action(self, action: str, context: Dict[str, Any]) -> List[EthicalDecision]:\n        """\n        Evaluate an action against ethical principles\n        """\n        decisions = []\n\n        # Check for harm prevention (non-maleficence)\n        harm_risk = self._assess_harm_risk(action, context)\n        if harm_risk > 0.5:\n            decisions.append(EthicalDecision(\n                action=action,\n                principle=EthicalPrinciple.NON_MALEFICENCE,\n                weight=1.0 - harm_risk,\n                justification=f"Action has {harm_risk:.2f} risk of harm"\n            ))\n\n        # Check for benefit (beneficence)\n        benefit = self._assess_benefit(action, context)\n        if benefit > 0.3:\n            decisions.append(EthicalDecision(\n                action=action,\n                principle=EthicalPrinciple.BENEFICENCE,\n                weight=benefit,\n                justification=f"Action provides {benefit:.2f} benefit"\n            ))\n\n        # Check for autonomy respect\n        autonomy_impact = self._assess_autonomy_impact(action, context)\n        if abs(autonomy_impact) > 0.2:\n            weight = abs(autonomy_impact)\n            principle = EthicalPrinciple.AUTONOMY if autonomy_impact > 0 else None\n            if principle:\n                decisions.append(EthicalDecision(\n                    action=action,\n                    principle=principle,\n                    weight=weight,\n                    justification=f"Action affects human autonomy by {autonomy_impact:.2f}"\n                ))\n\n        # Check for fairness\n        fairness_impact = self._assess_fairness(action, context)\n        if abs(fairness_impact) > 0.3:\n            weight = abs(fairness_impact)\n            principle = EthicalPrinciple.JUSTICE if fairness_impact > 0 else None\n            if principle:\n                decisions.append(EthicalDecision(\n                    action=action,\n                    principle=principle,\n                    weight=weight,\n                    justification=f"Action affects fairness by {fairness_impact:.2f}"\n                ))\n\n        self.decision_log.append({\n            \'action\': action,\n            \'context\': context,\n            \'decisions\': [d.__dict__ for d in decisions],\n            \'timestamp\': time.time()\n        })\n\n        return decisions\n\n    def _assess_harm_risk(self, action: str, context: Dict[str, Any]) -> float:\n        """Assess the risk of harm from an action"""\n        # Simplified assessment based on action type\n        harm_keywords = [\'push\', \'hit\', \'force\', \'aggressive\', \'dangerous\']\n        risk = sum(1 for keyword in harm_keywords if keyword.lower() in action.lower())\n        return min(risk / 3.0, 1.0)  # Normalize to 0-1 range\n\n    def _assess_benefit(self, action: str, context: Dict[str, Any]) -> float:\n        """Assess the benefit of an action"""\n        benefit_keywords = [\'help\', \'assist\', \'support\', \'aid\', \'assist\']\n        benefit = sum(1 for keyword in benefit_keywords if keyword.lower() in action.lower())\n        return min(benefit / 2.0, 1.0)  # Normalize to 0-1 range\n\n    def _assess_autonomy_impact(self, action: str, context: Dict[str, Any]) -> float:\n        """Assess impact on human autonomy"""\n        # Positive if supporting autonomy, negative if restricting it\n        if \'ask_permission\' in action.lower() or \'request_consent\' in action.lower():\n            return 0.8\n        elif \'override_human\' in action.lower() or \'disregard_human\' in action.lower():\n            return -0.9\n        return 0.0\n\n    def _assess_fairness(self, action: str, context: Dict[str, Any]) -> float:\n        """Assess fairness impact"""\n        # Simplified fairness assessment\n        if \'equal_treatment\' in context.get(\'goal\', \'\').lower():\n            return 0.7 if \'equal\' in action.lower() else -0.5\n        return 0.0\n\n    def make_ethical_decision(self, action: str, context: Dict[str, Any]) -> bool:\n        """\n        Make an ethical decision about whether to proceed with an action\n        """\n        decisions = self.evaluate_action(action, context)\n\n        if not decisions:\n            return True  # No ethical concerns, proceed\n\n        # Calculate overall ethical score\n        total_score = 0\n        total_weight = 0\n\n        for decision in decisions:\n            weight = self.principles[decision.principle]\n            score = decision.weight if decision.principle in [\n                EthicalPrinciple.BENEFICENCE, EthicalPrinciple.AUTONOMY,\n                EthicalPrinciple.JUSTICE, EthicalPrinciple.VERACITY,\n                EthicalPrinciple.FIDELITY\n            ] else (1 - decision.weight)  # For non-maleficence, lower risk is better\n\n            total_score += score * weight\n            total_weight += weight\n\n        if total_weight > 0:\n            avg_score = total_score / total_weight\n            return avg_score > 0.5  # Proceed if ethical score > 0.5\n        else:\n            return True\n\n# Example usage\ndef ethical_decision_example():\n    framework = EthicalFramework()\n\n    # Test various actions\n    actions = [\n        "assist_human_with_task",\n        "push_human_out_of_way",\n        "ask_permission_before_helping",\n        "ignore_human_request_for_help"\n    ]\n\n    context = {\n        "environment": "home",\n        "humans_present": 1,\n        "goal": "assist_with_daily_activities"\n    }\n\n    for action in actions:\n        should_proceed = framework.make_ethical_decision(action, context)\n        print(f"Action: {action} - Proceed: {should_proceed}")\n\n    return framework\n'})}),"\n",(0,i.jsx)(n.h2,{id:"privacy-and-data-protection",children:"Privacy and Data Protection"}),"\n",(0,i.jsx)(n.p,{children:"As humanoid robots collect and process vast amounts of personal data, privacy and data protection become critical ethical considerations. These systems often capture sensitive information including biometric data, behavioral patterns, and personal preferences."}),"\n",(0,i.jsx)(n.h3,{id:"data-minimization-and-consent",children:"Data Minimization and Consent"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example: Privacy Protection Framework for Robotic Systems\nimport hashlib\nimport secrets\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional\nimport json\n\nclass DataProtectionFramework:\n    def __init__(self):\n        self.collected_data = {}\n        self.consent_records = {}\n        self.retention_policies = {}\n        self.encryption_keys = {}\n\n    def request_consent(self, user_id: str, data_types: List[str], purpose: str, duration_hours: int) -> str:\n        \"\"\"\n        Request user consent for data collection\n        Returns consent token\n        \"\"\"\n        consent_token = secrets.token_urlsafe(32)\n\n        consent_record = {\n            'user_id': user_id,\n            'data_types': data_types,\n            'purpose': purpose,\n            'requested_at': datetime.now().isoformat(),\n            'expires_at': (datetime.now() + timedelta(hours=duration_hours)).isoformat(),\n            'granted': False\n        }\n\n        self.consent_records[consent_token] = consent_record\n        return consent_token\n\n    def grant_consent(self, consent_token: str) -> bool:\n        \"\"\"\n        Grant consent for data collection\n        \"\"\"\n        if consent_token in self.consent_records:\n            self.consent_records[consent_token]['granted'] = True\n            self.consent_records[consent_token]['granted_at'] = datetime.now().isoformat()\n            return True\n        return False\n\n    def collect_data(self, consent_token: str, data_type: str, data: any) -> bool:\n        \"\"\"\n        Collect data if consent is granted and valid\n        \"\"\"\n        if consent_token not in self.consent_records:\n            return False\n\n        consent = self.consent_records[consent_token]\n\n        # Check if consent is granted and not expired\n        if not consent['granted']:\n            return False\n\n        if datetime.fromisoformat(consent['expires_at']) < datetime.now():\n            return False\n\n        # Check if requested data type matches consent\n        if data_type not in consent['data_types']:\n            return False\n\n        # Encrypt and store data\n        encrypted_data = self._encrypt_data(data, consent['user_id'])\n\n        if consent['user_id'] not in self.collected_data:\n            self.collected_data[consent['user_id']] = {}\n\n        if data_type not in self.collected_data[consent['user_id']]:\n            self.collected_data[consent['user_id']][data_type] = []\n\n        self.collected_data[consent['user_id']][data_type].append({\n            'timestamp': datetime.now().isoformat(),\n            'data': encrypted_data,\n            'consent_token': consent_token\n        })\n\n        return True\n\n    def _encrypt_data(self, data: any, user_id: str) -> str:\n        \"\"\"\n        Encrypt data using user-specific key\n        \"\"\"\n        if user_id not in self.encryption_keys:\n            self.encryption_keys[user_id] = secrets.token_bytes(32)\n\n        key = self.encryption_keys[user_id]\n        # In real implementation, use proper encryption (e.g., Fernet)\n        # This is a simplified example\n        data_str = json.dumps(data, default=str)\n        encrypted = hashlib.sha256((data_str + key.hex()).encode()).hexdigest()\n        return encrypted\n\n    def anonymize_data(self, user_id: str, data_type: str) -> List[any]:\n        \"\"\"\n        Anonymize collected data by removing identifying information\n        \"\"\"\n        if user_id not in self.collected_data:\n            return []\n\n        if data_type not in self.collected_data[user_id]:\n            return []\n\n        # In real implementation, apply proper anonymization techniques\n        # This is a simplified example\n        anonymized_data = []\n        for record in self.collected_data[user_id][data_type]:\n            # Remove or hash identifying information\n            anonymized_data.append({\n                'timestamp': record['timestamp'],\n                'data_hash': hashlib.sha256(record['data'].encode()).hexdigest()[:16]\n            })\n\n        return anonymized_data\n\n    def set_retention_policy(self, data_type: str, days: int):\n        \"\"\"\n        Set data retention policy for specific data type\n        \"\"\"\n        self.retention_policies[data_type] = days\n\n    def cleanup_expired_data(self):\n        \"\"\"\n        Remove data that has exceeded retention period\n        \"\"\"\n        current_time = datetime.now()\n\n        for user_id, user_data in self.collected_data.items():\n            for data_type, records in user_data.items():\n                if data_type in self.retention_policies:\n                    retention_days = self.retention_policies[data_type]\n                    cutoff_date = current_time - timedelta(days=retention_days)\n\n                    # Filter out expired records\n                    filtered_records = [\n                        record for record in records\n                        if datetime.fromisoformat(record['timestamp']) >= cutoff_date\n                    ]\n\n                    self.collected_data[user_id][data_type] = filtered_records\n\n# Example usage\ndef privacy_example():\n    privacy_framework = DataProtectionFramework()\n\n    # Set retention policies\n    privacy_framework.set_retention_policy('face_recognition', 30)\n    privacy_framework.set_retention_policy('voice_data', 7)\n    privacy_framework.set_retention_policy('behavioral_data', 90)\n\n    # Request consent for face recognition\n    consent_token = privacy_framework.request_consent(\n        user_id='user_123',\n        data_types=['face_recognition', 'behavioral_data'],\n        purpose='personalized interaction',\n        duration_hours=24\n    )\n\n    print(f\"Consent requested. Token: {consent_token[:8]}...\")\n\n    # User grants consent\n    privacy_framework.grant_consent(consent_token)\n\n    # Collect face data\n    face_data = {\n        'landmarks': [[x, y] for x in range(10) for y in range(10)],\n        'confidence': 0.95\n    }\n\n    success = privacy_framework.collect_data(consent_token, 'face_recognition', face_data)\n    print(f\"Face data collection successful: {success}\")\n\n    # Anonymize data for analysis\n    anonymized = privacy_framework.anonymize_data('user_123', 'face_recognition')\n    print(f\"Anonymized records: {len(anonymized)}\")\n\n    return privacy_framework\n"})}),"\n",(0,i.jsx)(n.h2,{id:"human-robot-interaction-safety",children:"Human-Robot Interaction Safety"}),"\n",(0,i.jsx)(n.p,{children:"Safe human-robot interaction requires careful consideration of physical, psychological, and social factors. As humanoid robots become more common in human environments, ensuring safe and appropriate interaction becomes critical."}),"\n",(0,i.jsx)(n.h3,{id:"physical-safety-in-hri",children:"Physical Safety in HRI"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example: Human-Robot Interaction Safety Manager\nimport math\nimport numpy as np\nfrom typing import Tuple, List, Optional\n\nclass HRI_SafetyManager:\n    def __init__(self):\n        self.human_proximity_threshold = 0.5  # meters\n        self.collision_prediction_horizon = 1.0  # seconds\n        self.safety_zones = []\n        self.human_tracking = {}\n\n    def calculate_collision_risk(self, robot_pos: Tuple[float, float, float],\n                                robot_vel: Tuple[float, float, float],\n                                human_pos: Tuple[float, float, float],\n                                human_vel: Tuple[float, float, float]) -> float:\n        \"\"\"\n        Calculate collision risk between robot and human\n        Returns risk value between 0 and 1\n        \"\"\"\n        # Calculate relative position and velocity\n        rel_pos = np.array(robot_pos) - np.array(human_pos)\n        rel_vel = np.array(robot_vel) - np.array(human_vel)\n\n        # Distance between robot and human\n        distance = np.linalg.norm(rel_pos)\n\n        # Predict future positions\n        future_robot_pos = np.array(robot_pos) + np.array(robot_vel) * self.collision_prediction_horizon\n        future_human_pos = np.array(human_pos) + np.array(human_vel) * self.collision_prediction_horizon\n\n        future_distance = np.linalg.norm(future_robot_pos - future_human_pos)\n\n        # Calculate risk based on current and predicted distances\n        current_risk = max(0, 1 - distance / self.human_proximity_threshold)\n        future_risk = max(0, 1 - future_distance / self.human_proximity_threshold)\n\n        # Weight future risk more heavily as it represents predicted collision\n        risk = 0.3 * current_risk + 0.7 * future_risk\n\n        return min(risk, 1.0)\n\n    def enforce_safety_zone(self, robot_pos: Tuple[float, float, float],\n                           human_pos: Tuple[float, float, float]) -> Tuple[float, float, float]:\n        \"\"\"\n        Calculate safe movement vector to maintain minimum distance from human\n        \"\"\"\n        rel_vector = np.array(robot_pos) - np.array(human_pos)\n        distance = np.linalg.norm(rel_vector)\n\n        if distance < self.human_proximity_threshold:\n            # Calculate repulsive force\n            if distance < 0.1:  # Very close, strong repulsion\n                force_magnitude = 2.0\n            else:\n                # Inverse relationship: closer = stronger repulsion\n                force_magnitude = 0.5 / distance\n\n            # Normalize direction away from human\n            if distance > 0:\n                repulsion_vector = (rel_vector / distance) * force_magnitude\n            else:\n                # If exactly at human position, move in random direction\n                repulsion_vector = np.array([np.random.uniform(-1, 1) for _ in range(3)])\n                repulsion_vector = repulsion_vector / np.linalg.norm(repulsion_vector) * force_magnitude\n\n            return tuple(repulsion_vector)\n        else:\n            # No safety intervention needed\n            return (0.0, 0.0, 0.0)\n\n    def assess_interaction_safety(self, robot_state: Dict, human_states: List[Dict]) -> Dict:\n        \"\"\"\n        Assess overall safety of human-robot interaction\n        \"\"\"\n        safety_assessment = {\n            'collision_risk': 0.0,\n            'safety_zone_violations': 0,\n            'recommended_actions': [],\n            'overall_safety_score': 1.0\n        }\n\n        for human_state in human_states:\n            # Calculate collision risk\n            risk = self.calculate_collision_risk(\n                robot_state['position'],\n                robot_state['velocity'],\n                human_state['position'],\n                human_state['velocity']\n            )\n\n            safety_assessment['collision_risk'] = max(safety_assessment['collision_risk'], risk)\n\n            # Check safety zone violation\n            robot_pos = np.array(robot_state['position'])\n            human_pos = np.array(human_state['position'])\n            distance = np.linalg.norm(robot_pos - human_pos)\n\n            if distance < self.human_proximity_threshold:\n                safety_assessment['safety_zone_violations'] += 1\n                safety_assessment['recommended_actions'].append(\n                    f\"Maintain distance from human at {human_state['position']}\"\n                )\n\n        # Calculate overall safety score (inverse of risk)\n        safety_assessment['overall_safety_score'] = 1.0 - safety_assessment['collision_risk']\n\n        return safety_assessment\n\n# Example usage\ndef hri_safety_example():\n    safety_manager = HRI_SafetyManager()\n\n    # Robot state\n    robot_state = {\n        'position': (1.0, 0.5, 0.8),\n        'velocity': (0.1, 0.0, 0.0)\n    }\n\n    # Human states (multiple humans in environment)\n    human_states = [\n        {\n            'position': (0.8, 0.5, 0.8),\n            'velocity': (0.0, 0.0, 0.0)\n        },\n        {\n            'position': (2.0, 1.0, 0.8),\n            'velocity': (0.05, 0.0, 0.0)\n        }\n    ]\n\n    # Assess interaction safety\n    assessment = safety_manager.assess_interaction_safety(robot_state, human_states)\n\n    print(f\"Collision Risk: {assessment['collision_risk']:.2f}\")\n    print(f\"Safety Zone Violations: {assessment['safety_zone_violations']}\")\n    print(f\"Overall Safety Score: {assessment['overall_safety_score']:.2f}\")\n    print(f\"Recommended Actions: {assessment['recommended_actions']}\")\n\n    # Calculate safety zone enforcement\n    repulsion_force = safety_manager.enforce_safety_zone(\n        robot_state['position'],\n        human_states[0]['position']  # Check against closest human\n    )\n\n    print(f\"Repulsion Force Vector: {repulsion_force}\")\n\n    return safety_manager\n"})}),"\n",(0,i.jsx)(n.h2,{id:"ethical-ai-development-practices",children:"Ethical AI Development Practices"}),"\n",(0,i.jsx)(n.p,{children:"Developing ethical AI systems requires adherence to principles that ensure fairness, transparency, accountability, and respect for human rights. These principles must be embedded throughout the development lifecycle."}),"\n",(0,i.jsx)(n.h3,{id:"fairness-and-bias-mitigation",children:"Fairness and Bias Mitigation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example: Fairness and Bias Detection in Robotic AI Systems\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict, List, Any\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\nclass FairnessChecker:\n    def __init__(self):\n        self.protected_attributes = []\n        self.bias_metrics = {}\n        self.fairness_threshold = 0.1  # Maximum acceptable bias difference\n\n    def add_protected_attribute(self, attribute: str):\n        \"\"\"Add a protected attribute for bias checking\"\"\"\n        if attribute not in self.protected_attributes:\n            self.protected_attributes.append(attribute)\n\n    def calculate_disparate_impact(self, predictions: List[int],\n                                  actual: List[int],\n                                  protected_group: List[bool],\n                                  favorable_outcome: int = 1) -> float:\n        \"\"\"\n        Calculate disparate impact ratio\n        Returns ratio of favorable outcomes between protected and unprotected groups\n        \"\"\"\n        protected_favorable = sum(1 for i, pred in enumerate(predictions)\n                                 if protected_group[i] and pred == favorable_outcome)\n        protected_total = sum(1 for p in protected_group if p)\n\n        unprotected_favorable = sum(1 for i, pred in enumerate(predictions)\n                                   if not protected_group[i] and pred == favorable_outcome)\n        unprotected_total = sum(1 for p in protected_group if not p)\n\n        if unprotected_total == 0 or protected_total == 0:\n            return 1.0  # Cannot calculate if one group has no members\n\n        protected_rate = protected_favorable / protected_total\n        unprotected_rate = unprotected_favorable / unprotected_total\n\n        if unprotected_rate == 0:\n            return float('inf') if protected_rate > 0 else 1.0\n\n        return protected_rate / unprotected_rate\n\n    def detect_bias_in_robot_behavior(self, robot_decisions: List[Dict]) -> Dict:\n        \"\"\"\n        Detect potential bias in robot decision-making\n        \"\"\"\n        bias_report = {}\n\n        for attr in self.protected_attributes:\n            # Group decisions by protected attribute\n            groups = {}\n            for decision in robot_decisions:\n                attr_value = decision.get(attr, 'unknown')\n                if attr_value not in groups:\n                    groups[attr_value] = []\n                groups[attr_value].append(decision)\n\n            # Calculate performance metrics for each group\n            group_metrics = {}\n            for group_value, group_decisions in groups.items():\n                if len(group_decisions) == 0:\n                    continue\n\n                predictions = [d.get('prediction', 0) for d in group_decisions]\n                actual = [d.get('actual', 0) for d in group_decisions]\n\n                if len(set(actual)) > 1:  # Need both positive and negative cases\n                    group_metrics[group_value] = {\n                        'accuracy': accuracy_score(actual, predictions),\n                        'precision': precision_score(actual, predictions, zero_division=0),\n                        'recall': recall_score(actual, predictions, zero_division=0),\n                        'count': len(group_decisions)\n                    }\n\n            # Check for bias between groups\n            if len(group_metrics) > 1:\n                metric_values = {metric: [g[metric] for g in group_metrics.values()]\n                               for metric in ['accuracy', 'precision', 'recall']}\n\n                bias_detected = False\n                for metric, values in metric_values.items():\n                    if len(values) > 1:\n                        max_diff = max(values) - min(values)\n                        if max_diff > self.fairness_threshold:\n                            bias_detected = True\n\n                bias_report[attr] = {\n                    'metrics': group_metrics,\n                    'bias_detected': bias_detected,\n                    'max_difference': max([max(v) - min(v) for v in metric_values.values()]) if metric_values else 0\n                }\n\n        return bias_report\n\n    def recommend_bias_mitigation(self, bias_report: Dict) -> List[str]:\n        \"\"\"\n        Recommend bias mitigation strategies\n        \"\"\"\n        recommendations = []\n\n        for attr, report in bias_report.items():\n            if report['bias_detected']:\n                recommendations.append(\n                    f\"Significant bias detected in {attr} attribute. \"\n                    f\"Max difference: {report['max_difference']:.3f}. \"\n                    f\"Consider: {self._get_mitigation_strategies(attr)}\"\n                )\n\n        return recommendations\n\n    def _get_mitigation_strategies(self, attribute: str) -> str:\n        \"\"\"\n        Get appropriate mitigation strategies for specific attribute\n        \"\"\"\n        strategies = {\n            'gender': \"Data balancing, adversarial debiasing, fairness constraints\",\n            'age': \"Stratified sampling, age-aware training, regular bias audits\",\n            'race': \"Diverse training data, bias detection tools, inclusive design\",\n            'disability': \"Accessibility features, universal design, bias testing\"\n        }\n        return strategies.get(attribute, \"Data auditing, bias detection, fairness constraints\")\n\n# Example usage\ndef fairness_example():\n    fairness_checker = FairnessChecker()\n    fairness_checker.add_protected_attribute('gender')\n    fairness_checker.add_protected_attribute('age_group')\n\n    # Simulated robot decisions\n    robot_decisions = [\n        {'gender': 'male', 'age_group': 'adult', 'prediction': 1, 'actual': 1},\n        {'gender': 'female', 'age_group': 'adult', 'prediction': 0, 'actual': 1},\n        {'gender': 'male', 'age_group': 'elderly', 'prediction': 1, 'actual': 1},\n        {'gender': 'female', 'age_group': 'adult', 'prediction': 1, 'actual': 0},\n        {'gender': 'male', 'age_group': 'adult', 'prediction': 1, 'actual': 1},\n        {'gender': 'female', 'age_group': 'elderly', 'prediction': 0, 'actual': 0},\n    ]\n\n    # Detect bias\n    bias_report = fairness_checker.detect_bias_in_robot_behavior(robot_decisions)\n\n    print(\"Bias Report:\")\n    for attr, report in bias_report.items():\n        print(f\"  {attr}: Bias detected = {report['bias_detected']}\")\n        print(f\"  Max difference: {report['max_difference']:.3f}\")\n\n    # Get recommendations\n    recommendations = fairness_checker.recommend_bias_mitigation(bias_report)\n    print(\"\\nRecommendations:\")\n    for rec in recommendations:\n        print(f\"  - {rec}\")\n\n    return fairness_checker\n"})}),"\n",(0,i.jsx)(n.h2,{id:"hardware-specific-safety-implementations",children:"Hardware-Specific Safety Implementations"}),"\n",(0,i.jsx)(n.p,{children:"Different hardware platforms require tailored safety approaches based on their capabilities and limitations:"}),"\n",(0,i.jsx)(n.h3,{id:"gpu-accelerated-safety-systems",children:"GPU-Accelerated Safety Systems"}),"\n",(0,i.jsx)(n.p,{children:"For robots with powerful GPUs, we can implement more sophisticated safety algorithms:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-jsx",children:"// Example: GPU-Accelerated Safety System Component (React/Preact)\nimport React, { useState, useEffect, useRef } from 'react';\n\nconst GPUSafetySystem = ({ robotSpecs }) => {\n  const [safetyStatus, setSafetyStatus] = useState('normal');\n  const [detectedHazards, setDetectedHazards] = useState([]);\n  const [performanceMetrics, setPerformanceMetrics] = useState({\n    detectionRate: 0,\n    latency: 0,\n    gpuUsage: 0\n  });\n\n  const canvasRef = useRef(null);\n  const animationRef = useRef(null);\n\n  useEffect(() => {\n    if (robotSpecs.gpuModel) {\n      initializeGPUSafetySystem();\n    }\n\n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current);\n      }\n    };\n  }, [robotSpecs]);\n\n  const initializeGPUSafetySystem = () => {\n    // Initialize GPU-accelerated safety algorithms\n    const gpuCapabilities = analyzeGPUCapabilities(robotSpecs.gpuModel);\n\n    if (gpuCapabilities.tensorCoreSupport) {\n      // Enable advanced safety features\n      enableAdvancedSafetyFeatures();\n    }\n  };\n\n  const analyzeGPUCapabilities = (gpuModel) => {\n    // Determine GPU capabilities for safety system\n    const capabilities = {\n      tensorCoreSupport: gpuModel.includes('RTX') || gpuModel.includes('Tesla'),\n      computeCapability: extractComputeCapability(gpuModel),\n      memorySize: robotSpecs.gpuMemory || 8192,\n      safetyFeaturesEnabled: true\n    };\n\n    return capabilities;\n  };\n\n  const extractComputeCapability = (gpuModel) => {\n    // Simplified compute capability extraction\n    if (gpuModel.includes('RTX 40')) return 8.9;\n    if (gpuModel.includes('RTX 30')) return 8.6;\n    if (gpuModel.includes('RTX 20')) return 7.5;\n    return 6.0;\n  };\n\n  const enableAdvancedSafetyFeatures = () => {\n    // Enable GPU-accelerated computer vision for hazard detection\n    setInterval(() => {\n      const hazards = detectHazardsWithGPU();\n      setDetectedHazards(hazards);\n\n      // Update safety status based on detected hazards\n      const status = hazards.length > 0 ? 'warning' : 'normal';\n      setSafetyStatus(status);\n\n      // Update performance metrics\n      setPerformanceMetrics(prev => ({\n        ...prev,\n        detectionRate: Math.random() * 60 + 30, // 30-90 FPS\n        latency: Math.random() * 10 + 5, // 5-15ms\n        gpuUsage: Math.random() * 70 + 20 // 20-90%\n      }));\n    }, 100); // 10Hz update rate\n  };\n\n  const detectHazardsWithGPU = () => {\n    // Simulate GPU-accelerated hazard detection\n    const possibleHazards = [\n      'human_proximity',\n      'obstacle_detected',\n      'unstable_surface',\n      'restricted_area'\n    ];\n\n    // Return random hazards based on probability\n    return possibleHazards.filter(() => Math.random() > 0.7);\n  };\n\n  const getSafetyStatusColor = () => {\n    switch(safetyStatus) {\n      case 'normal': return '#4ade80'; // green-400\n      case 'warning': return '#fbbf24'; // amber-400\n      case 'critical': return '#ef4444'; // red-400\n      default: return '#6b7280'; // gray-400\n    }\n  };\n\n  return (\n    <div className=\"gpu-safety-container\">\n      <h3>GPU-Accelerated Safety System</h3>\n\n      <div className=\"safety-status\" style={{ backgroundColor: getSafetyStatusColor() }}>\n        Status: {safetyStatus.toUpperCase()}\n      </div>\n\n      {detectedHazards.length > 0 && (\n        <div className=\"hazards-detected\">\n          <h4>Hazards Detected:</h4>\n          <ul>\n            {detectedHazards.map((hazard, index) => (\n              <li key={index} className=\"hazard-item\">\n                {hazard.replace('_', ' ').replace(/\\b\\w/g, l => l.toUpperCase())}\n              </li>\n            ))}\n          </ul>\n        </div>\n      )}\n\n      <div className=\"performance-metrics\">\n        <p>Detection Rate: {performanceMetrics.detectionRate.toFixed(1)} FPS</p>\n        <p>Latency: {performanceMetrics.latency.toFixed(1)} ms</p>\n        <p>GPU Usage: {performanceMetrics.gpuUsage.toFixed(1)}%</p>\n      </div>\n\n      <canvas\n        ref={canvasRef}\n        className=\"safety-visualization\"\n        width={400}\n        height={300}\n      />\n    </div>\n  );\n};\n\nexport default GPUSafetySystem;\n"})}),"\n",(0,i.jsx)(n.h3,{id:"jetson-based-safety-systems",children:"Jetson-Based Safety Systems"}),"\n",(0,i.jsx)(n.p,{children:"For NVIDIA Jetson platforms, we implement optimized safety algorithms:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Example: Jetson-Specific Safety System\nimport jetson.inference\nimport jetson.utils\nimport numpy as np\nimport time\nimport threading\n\nclass JetsonSafetySystem:\n    def __init__(self, jetson_model="jetson_nano"):\n        self.jetson_model = jetson_model\n        self.is_jetson = self.detect_jetson_platform()\n        self.safety_enabled = True\n        self.hazard_detection_thread = None\n        self.emergency_stop = False\n\n        if self.is_jetson:\n            self.configure_jetson_safety()\n\n    def detect_jetson_platform(self):\n        """Detect if running on NVIDIA Jetson"""\n        try:\n            with open(\'/proc/device-tree/model\', \'r\') as f:\n                model = f.read().strip(\'\\x00\')\n                return \'jetson\' in model.lower()\n        except:\n            return False\n\n    def configure_jetson_safety(self):\n        """Configure safety system for Jetson platform"""\n        # Enable Jetson-specific optimizations\n        self.use_tensorrt = True\n        self.power_mode = "MAXN"  # Maximum performance mode\n\n        # Set up hazard detection model optimized for Jetson\n        self.setup_hazard_detection_model()\n\n    def setup_hazard_detection_model(self):\n        """Set up optimized hazard detection model for Jetson"""\n        # In a real implementation, this would load a TensorRT-optimized model\n        # For simulation, we\'ll use a placeholder\n        self.hazard_detection_model = self.load_optimized_model()\n\n    def load_optimized_model(self):\n        """Load safety model optimized for Jetson"""\n        # Placeholder for actual model loading\n        # In practice, this would load a TensorRT engine\n        return {\n            \'model_type\': \'tensorrt\',\n            \'input_size\': (224, 224, 3),\n            \'classes\': [\'human\', \'obstacle\', \'hazard\', \'safe\']\n        }\n\n    def detect_hazards_jetson(self, image_data):\n        """Perform hazard detection optimized for Jetson"""\n        if not self.is_jetson or not self.safety_enabled:\n            return {\'hazards\': [], \'confidence\': 0.0}\n\n        # Process image through optimized model\n        # In real implementation, this would use jetson.inference\n        hazards = self.simulate_jetson_hazard_detection(image_data)\n\n        return hazards\n\n    def simulate_jetson_hazard_detection(self, image_data):\n        """Simulate hazard detection (in real implementation, use actual Jetson inference)"""\n        # Simulate detection with Jetson-specific characteristics\n        detection_time = np.random.uniform(0.02, 0.05)  # 20-50ms typical for Jetson\n        time.sleep(detection_time)  # Simulate processing time\n\n        # Return simulated detection results\n        possible_hazards = [\'human_proximity\', \'obstacle\', \'slippery_surface\']\n        detected = [h for h in possible_hazards if np.random.random() > 0.8]\n\n        return {\n            \'hazards\': detected,\n            \'confidence\': np.random.uniform(0.7, 0.95),\n            \'processing_time\': detection_time\n        }\n\n    def start_hazard_monitoring(self):\n        """Start continuous hazard monitoring on Jetson"""\n        if not self.is_jetson:\n            print("Not running on Jetson - hazard monitoring unavailable")\n            return\n\n        self.hazard_detection_thread = threading.Thread(target=self.hazard_monitoring_loop)\n        self.hazard_detection_thread.daemon = True\n        self.hazard_detection_thread.start()\n\n    def hazard_monitoring_loop(self):\n        """Continuous hazard monitoring loop"""\n        while self.safety_enabled and not self.emergency_stop:\n            # Simulate getting image data from robot\'s cameras\n            dummy_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n\n            # Perform hazard detection\n            detection_result = self.detect_hazards_jetson(dummy_image)\n\n            # Check for critical hazards\n            if \'human_proximity\' in detection_result[\'hazards\']:\n                self.trigger_safety_response(\'human_proximity\')\n            elif \'obstacle\' in detection_result[\'hazards\']:\n                self.trigger_safety_response(\'obstacle_detected\')\n\n            # Small delay to prevent excessive CPU usage\n            time.sleep(0.05)  # 20Hz monitoring\n\n    def trigger_safety_response(self, hazard_type):\n        """Trigger appropriate safety response"""\n        print(f"Safety response triggered for: {hazard_type}")\n\n        # In real implementation, this would send commands to robot\n        # to take appropriate safety actions\n        if hazard_type == \'human_proximity\':\n            # Slow down or stop movement toward human\n            self.slow_down_robot()\n        elif hazard_type == \'obstacle\':\n            # Navigate around obstacle\n            self.navigate_around_obstacle()\n\n    def slow_down_robot(self):\n        """Send command to slow down robot movement"""\n        print("Slowing down robot for safety")\n\n    def navigate_around_obstacle(self):\n        """Send command to navigate around obstacle"""\n        print("Navigating around obstacle")\n\n    def enable_safety(self):\n        """Enable safety system"""\n        self.safety_enabled = True\n        if self.is_jetson:\n            self.start_hazard_monitoring()\n\n    def disable_safety(self):\n        """Disable safety system (use with caution)"""\n        self.safety_enabled = False\n        self.emergency_stop = False\n\n# Example usage\ndef jetson_safety_example():\n    safety_system = JetsonSafetySystem(jetson_model="jetson_xavier_nx")\n\n    if safety_system.is_jetson:\n        print("Jetson safety system initialized")\n        safety_system.enable_safety()\n\n        # Run for 10 seconds\n        time.sleep(10)\n\n        safety_system.disable_safety()\n        print("Safety system disabled")\n    else:\n        print("Not running on Jetson platform")\n\n    return safety_system\n'})}),"\n",(0,i.jsx)(n.h3,{id:"real-robot-safety-integration",children:"Real Robot Safety Integration"}),"\n",(0,i.jsx)(n.p,{children:"For robots with real hardware, we need comprehensive safety integration:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Example: Real Robot Safety Integration\nimport rospy\nfrom sensor_msgs.msg import LaserScan, Image\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import Bool\nimport cv2\nimport numpy as np\nimport threading\nimport time\n\nclass RealRobotSafety:\n    def __init__(self, robot_type="unitree_go2"):\n        self.robot_type = robot_type\n        self.safety_enabled = True\n        self.emergency_stop_active = False\n        self.laser_scan_data = None\n        self.camera_data = None\n\n        # Initialize ROS nodes and subscribers\n        rospy.init_node(\'robot_safety_node\', anonymous=True)\n\n        # Subscribe to sensor data\n        self.laser_sub = rospy.Subscriber(\'/scan\', LaserScan, self.laser_callback)\n        self.camera_sub = rospy.Subscriber(\'/camera/image_raw\', Image, self.camera_callback)\n\n        # Publisher for safety commands\n        self.cmd_pub = rospy.Publisher(\'/cmd_vel\', Twist, queue_size=10)\n        self.emergency_stop_pub = rospy.Publisher(\'/emergency_stop\', Bool, queue_size=1)\n\n        # Safety parameters\n        self.min_obstacle_distance = 0.5  # meters\n        self.human_detection_threshold = 0.7  # confidence\n        self.safety_thread = None\n\n    def laser_callback(self, data):\n        """Callback for laser scan data"""\n        self.laser_scan_data = data\n\n    def camera_callback(self, data):\n        """Callback for camera data"""\n        # Convert ROS Image to OpenCV format\n        try:\n            # In real implementation, use cv_bridge\n            # For simulation, we\'ll process the raw data\n            self.camera_data = data\n        except Exception as e:\n            print(f"Camera callback error: {e}")\n\n    def check_laser_safety(self):\n        """Check laser scan data for obstacles"""\n        if self.laser_scan_data is None:\n            return True  # Can\'t determine safety, assume safe\n\n        # Check for obstacles within safety distance\n        min_distance = min(self.laser_scan_data.ranges)\n\n        if min_distance < self.min_obstacle_distance:\n            return False  # Obstacle too close\n\n        return True\n\n    def check_camera_safety(self):\n        """Check camera data for humans or hazards"""\n        if self.camera_data is None:\n            return True  # Can\'t determine safety, assume safe\n\n        # In real implementation, run object detection on camera image\n        # For simulation, return True\n        return True\n\n    def run_safety_check(self):\n        """Run comprehensive safety check"""\n        laser_safe = self.check_laser_safety()\n        camera_safe = self.check_camera_safety()\n\n        return laser_safe and camera_safe\n\n    def enforce_safety(self):\n        """Enforce safety by controlling robot movement"""\n        if not self.safety_enabled:\n            return\n\n        is_safe = self.run_safety_check()\n\n        if not is_safe:\n            # Emergency stop\n            self.activate_emergency_stop()\n        else:\n            # Deactivate emergency stop if active\n            if self.emergency_stop_active:\n                self.deactivate_emergency_stop()\n\n    def activate_emergency_stop(self):\n        """Activate emergency stop"""\n        if not self.emergency_stop_active:\n            print("EMERGENCY STOP ACTIVATED")\n\n            # Send stop command\n            stop_cmd = Twist()\n            self.cmd_pub.publish(stop_cmd)\n\n            # Publish emergency stop signal\n            emergency_msg = Bool()\n            emergency_msg.data = True\n            self.emergency_stop_pub.publish(emergency_msg)\n\n            self.emergency_stop_active = True\n\n    def deactivate_emergency_stop(self):\n        """Deactivate emergency stop"""\n        if self.emergency_stop_active:\n            print("EMERGENCY STOP DEACTIVATED")\n\n            # Publish emergency stop release\n            emergency_msg = Bool()\n            emergency_msg.data = False\n            self.emergency_stop_pub.publish(emergency_msg)\n\n            self.emergency_stop_active = False\n\n    def start_safety_monitoring(self):\n        """Start continuous safety monitoring"""\n        self.safety_thread = threading.Thread(target=self.safety_loop)\n        self.safety_thread.daemon = True\n        self.safety_thread.start()\n\n    def safety_loop(self):\n        """Continuous safety monitoring loop"""\n        rate = rospy.Rate(20)  # 20Hz safety check\n\n        while not rospy.is_shutdown() and self.safety_enabled:\n            try:\n                self.enforce_safety()\n            except Exception as e:\n                print(f"Safety loop error: {e}")\n\n            rate.sleep()\n\n    def enable_safety(self):\n        """Enable safety system"""\n        self.safety_enabled = True\n        self.start_safety_monitoring()\n\n    def disable_safety(self):\n        """Disable safety system"""\n        self.safety_enabled = False\n        self.deactivate_emergency_stop()\n\n# Example usage\ndef real_robot_safety_example():\n    safety_system = RealRobotSafety(robot_type="unitree_go2")\n\n    print("Real robot safety system initialized")\n    safety_system.enable_safety()\n\n    try:\n        # Keep running until interrupted\n        rospy.spin()\n    except KeyboardInterrupt:\n        print("Safety system shutting down")\n        safety_system.disable_safety()\n\n    return safety_system\n'})}),"\n",(0,i.jsx)(n.h2,{id:"urdu-content-\u0633\u06cc\u0641\u0679\u06cc-\u0627\u0648\u0631-\u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a",children:"Urdu Content: \u0633\u06cc\u0641\u0679\u06cc \u0627\u0648\u0631 \u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a"}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:"\u0627\u0631\u062f\u0648 \u0645\u06cc\u06ba \u067e\u0691\u06be\u06cc\u06ba / Show in Urdu"}),(0,i.jsx)(n.h1,{id:"\u0628\u0627\u0628-11-\u0631\u0648\u0628\u0648\u0679\u06a9\u0633-\u0645\u06cc\u06ba-\u0633\u06cc\u0641\u0679\u06cc-\u0627\u0648\u0631-\u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a",children:"\u0628\u0627\u0628 11: \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0645\u06cc\u06ba \u0633\u06cc\u0641\u0679\u06cc \u0627\u0648\u0631 \u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a"}),(0,i.jsx)(n.h2,{id:"\u062a\u0639\u0627\u0631\u0641",children:"\u062a\u0639\u0627\u0631\u0641"}),(0,i.jsx)(n.p,{children:'"\u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0645\u06cc\u06ba \u0633\u06cc\u0641\u0679\u06cc \u0627\u0648\u0631 \u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a" \u06a9\u0627 \u0628\u0627\u0628 11 \u0622\u067e \u06a9\u0648 \u0641\u0632\u06cc\u06a9\u0644 \u0627\u06cc \u0622\u0626\u06cc \u0627\u0648\u0631 \u06c1\u06cc\u0648\u0645\u0646\u0648\u0627\u0626\u0688 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u06a9\u06d2 \u0679\u06cc\u06a9\u0633\u0679 \u0628\u06a9 \u0645\u06cc\u06ba \u062e\u0648\u0634 \u0622\u0645\u062f\u06cc\u062f \u06a9\u06c1\u062a\u0627 \u06c1\u06d2\u06d4 \u06cc\u06c1 \u0628\u0627\u0628 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u06a9\u06d2 \u062a\u0631\u0642\u06cc \u06a9\u06d2 \u0627\u06cc\u06a9 \u0627\u0646\u062a\u06c1\u0627\u0626\u06cc \u0627\u06c1\u0645 \u067e\u06c1\u0644\u0648 \u06a9\u0648 \u062d\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2: \u0633\u06cc\u0641\u0679\u06cc \u0627\u0648\u0631 \u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a\u06d4 \u062c\u06cc\u0633\u06d2 \u062c\u06cc\u0633\u06d2 \u06c1\u06cc\u0648\u0645\u0646\u0648\u0627\u0626\u0688 \u0631\u0648\u0628\u0648\u0679\u0633 \u0632\u06cc\u0627\u062f\u06c1 \u062a\u0631\u0642\u06cc \u06cc\u0627\u0641\u062a\u06c1 \u06c1\u0648\u062a\u06d2 \u062c\u0627\u062a\u06d2 \u06c1\u06cc\u06ba \u0627\u0648\u0631 \u0627\u0646\u0633\u0627\u0646\u06cc \u0645\u0627\u062d\u0648\u0644 \u0645\u06cc\u06ba \u0645\u0631\u0628\u0648\u0637 \u06c1\u0648\u062a\u06d2 \u062c\u0627\u062a\u06d2 \u06c1\u06cc\u06ba\u060c \u0627\u0646 \u06a9\u06d2 \u0645\u062d\u0641\u0648\u0638 \u06a9\u0627\u0645 \u06a9\u0631\u0646\u06d2 \u0627\u0648\u0631 \u0627\u062e\u0644\u0627\u0642\u06cc \u0637\u0631\u0632 \u0639\u0645\u0644 \u06a9\u0648 \u06cc\u0642\u06cc\u0646\u06cc \u0628\u0646\u0627\u0646\u0627 \u0627\u0646\u062a\u06c1\u0627\u0626\u06cc \u0627\u06c1\u0645 \u06c1\u0648 \u062c\u0627\u062a\u0627 \u06c1\u06d2\u06d4'}),(0,i.jsx)(n.p,{children:"\u06cc\u06c1 \u0628\u0627\u0628 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0633\u0633\u0679\u0645\u0632 \u06a9\u06cc \u062a\u0631\u0642\u06cc \u0645\u06cc\u06ba \u0645\u062d\u0641\u0648\u0638 \u0627\u0648\u0631 \u0627\u062e\u0644\u0627\u0642\u06cc \u06c1\u0648\u0646\u06d2 \u06a9\u06d2 \u0645\u062a\u0639\u0644\u0642 \u0645\u06a9\u0645\u0644 \u0686\u06cc\u0644\u0646\u062c\u0648\u06ba \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1 \u0644\u06cc\u062a\u0627 \u06c1\u06d2\u06d4 \u06c1\u0645 \u0633\u06cc\u0641\u0679\u06cc \u067e\u0631\u0648\u0679\u0648\u06a9\u0648\u0644\u0632\u060c \u0627\u062e\u0644\u0627\u0642\u06cc \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9\u0633\u060c \u0631\u0633\u06a9 \u0627\u06cc\u0633\u06cc\u0633\u0645\u0646\u0679 \u06a9\u06cc \u0645\u06cc\u062a\u06be\u0648\u0688\u0648\u0644\u0648 \u062c\u06cc\u0632\u060c \u0627\u0648\u0631 \u0630\u0645\u06c1 \u062f\u0627\u0631\u0627\u0646\u06c1 \u062a\u0631\u0642\u06cc \u06a9\u06cc \u0645\u0634\u0642\u06cc\u06ba \u062a\u0644\u0627\u0634 \u06a9\u0631\u06cc\u06ba \u06af\u06d2 \u062c\u0648 \u06cc\u0642\u06cc\u0646\u06cc \u0628\u0646\u0627\u062a\u06cc \u06c1\u06cc\u06ba \u06a9\u06c1 \u06c1\u06cc\u0648\u0645\u0646\u0648\u0627\u0626\u0688 \u0631\u0648\u0628\u0648\u0679\u0633 \u0627\u0646\u0633\u0627\u0646\u0648\u06ba \u06a9\u06d2 \u0633\u0627\u062a\u06be \u0645\u062d\u0641\u0648\u0638 \u0637\u0631\u06cc\u0642\u06d2 \u0633\u06d2 \u06a9\u0627\u0645 \u06a9\u0631 \u0633\u06a9\u06cc\u06ba \u062c\u0628\u06a9\u06c1 \u0627\u062e\u0644\u0627\u0642\u06cc \u0627\u0635\u0648\u0644\u0648\u06ba \u0627\u0648\u0631 \u0645\u0639\u0627\u0634\u0631\u062a\u06cc \u0627\u0642\u062f\u0627\u0631 \u06a9\u0627 \u0627\u062d\u062a\u0631\u0627\u0645 \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba\u06d4"}),(0,i.jsx)(n.p,{children:"\u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0645\u06cc\u06ba \u0633\u06cc\u0641\u0679\u06cc \u0627\u0648\u0631 \u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a \u06a9\u06cc \u0627\u06c1\u0645\u06cc\u062a \u06a9\u0648 \u0646\u0638\u0631 \u0627\u0646\u062f\u0627\u0632 \u0646\u06c1\u06cc\u06ba \u06a9\u06cc\u0627 \u062c\u0627 \u0633\u06a9\u062a\u0627\u06d4 \u062c\u06cc\u0633\u06d2 \u062c\u06cc\u0633\u06d2 \u06cc\u06c1 \u0633\u0633\u0679\u0645\u0632 \u0632\u06cc\u0627\u062f\u06c1 \u062e\u0648\u062f \u0645\u062e\u062a\u0627\u0631 \u0627\u0648\u0631 \u0642\u0627\u0628\u0644 \u06c1\u0648\u062a\u06d2 \u062c\u0627\u062a\u06d2 \u06c1\u06cc\u06ba\u060c \u0646\u0627\u06a9\u0627\u0645\u06cc \u06cc\u0627 \u063a\u06cc\u0631 \u0627\u062e\u0644\u0627\u0642\u06cc \u0637\u0631\u0632 \u0639\u0645\u0644 \u06a9\u06d2 \u0646\u062a\u0627\u0626\u062c \u0628\u06d2 \u062a\u062d\u0627\u0634\u0627 \u0628\u0691\u06be \u062c\u0627\u062a\u06d2 \u06c1\u06cc\u06ba\u06d4 \u06cc\u06c1 \u0628\u0627\u0628 \u06c1\u06cc\u0648\u0645\u0646\u0648\u0627\u0626\u0688 \u0631\u0648\u0628\u0648\u0679\u0633 \u06a9\u06cc \u062a\u0631\u0642\u06cc \u0645\u06cc\u06ba \u0627\u0646 \u0686\u06cc\u0644\u0646\u062c\u0648\u06ba \u06a9\u0627 \u0633\u0627\u0645\u0646\u0627 \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0627\u06cc\u06a9 \u062c\u0627\u0645\u0639 \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9 \u0641\u0631\u0627\u06c1\u0645 \u06a9\u0631\u062a\u0627 \u06c1\u06d2\u06d4"}),(0,i.jsx)(n.h2,{id:"\u0633\u06cc\u0641\u0679\u06cc-\u067e\u0631\u0648\u0679\u0648\u06a9\u0648\u0644\u0632-\u0627\u0648\u0631-\u0645\u0639\u06cc\u0627\u0631\u0627\u062a",children:"\u0633\u06cc\u0641\u0679\u06cc \u067e\u0631\u0648\u0679\u0648\u06a9\u0648\u0644\u0632 \u0627\u0648\u0631 \u0645\u0639\u06cc\u0627\u0631\u0627\u062a"}),(0,i.jsx)(n.p,{children:"\u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0645\u06cc\u06ba \u0633\u06cc\u0641\u0679\u06cc \u0645\u06cc\u06ba \u0646\u06c1 \u0635\u0631\u0641 \u062c\u0633\u0645\u0627\u0646\u06cc \u0633\u06cc\u0641\u0679\u06cc (\u0627\u0646\u0633\u0627\u0646\u0648\u06ba \u0627\u0648\u0631 \u0645\u0627\u062d\u0648\u0644 \u06a9\u0648 \u0646\u0642\u0635\u0627\u0646 \u0633\u06d2 \u0628\u0686\u0627\u0646\u0627) \u0628\u0644\u06a9\u06c1 \u0622\u067e\u0631\u06cc\u0634\u0646\u0644 \u0633\u06cc\u0641\u0679\u06cc (\u0642\u0627\u0628\u0644 \u0627\u0639\u062a\u0645\u0627\u062f \u0627\u0648\u0631 \u0642\u0627\u0628\u0644 \u067e\u06cc\u0634 \u06af\u0648\u0626\u06cc \u0631\u0648\u0628\u0648\u0679 \u06a9\u06d2 \u0637\u0631\u0632 \u0639\u0645\u0644 \u06a9\u0648 \u06cc\u0642\u06cc\u0646\u06cc \u0628\u0646\u0627\u0646\u0627) \u0634\u0627\u0645\u0644 \u06c1\u06d2\u06d4 \u06c1\u06cc\u0648\u0645\u0646\u0648\u0627\u0626\u0688 \u0631\u0648\u0628\u0648\u0679\u0633 \u06a9\u06d2 \u062d\u0642\u06cc\u0642\u06cc \u062f\u0646\u06cc\u0627 \u06a9\u06d2 \u0645\u0627\u062d\u0648\u0644 \u0645\u06cc\u06ba \u0627\u062a\u0627\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0645\u06a9\u0645\u0644 \u0633\u06cc\u0641\u0679\u06cc \u067e\u0631\u0648\u0679\u0648\u06a9\u0648\u0644\u0632 \u06a9\u06cc \u062a\u0631\u0642\u06cc \u0636\u0631\u0648\u0631\u06cc \u06c1\u06d2\u06d4"}),(0,i.jsx)(n.h3,{id:"\u0628\u06cc\u0646-\u0627\u0644\u0627\u0642\u0648\u0627\u0645\u06cc-\u0633\u06cc\u0641\u0679\u06cc-\u0645\u0639\u06cc\u0627\u0631\u0627\u062a",children:"\u0628\u06cc\u0646 \u0627\u0644\u0627\u0642\u0648\u0627\u0645\u06cc \u0633\u06cc\u0641\u0679\u06cc \u0645\u0639\u06cc\u0627\u0631\u0627\u062a"}),(0,i.jsx)(n.p,{children:"\u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0635\u0646\u0639\u062a \u0646\u06d2 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0633\u0633\u0679\u0645\u0632 \u06a9\u06cc \u0688\u06cc\u0632\u0627\u0626\u0646 \u0627\u0648\u0631 \u0622\u067e\u0631\u06cc\u0634\u0646 \u06a9\u06cc \u06c1\u062f\u0627\u06cc\u062a \u06a9\u06d2 \u0644\u06cc\u06d2 \u06a9\u0626\u06cc \u06a9\u0644\u06cc\u062f\u06cc \u0633\u06cc\u0641\u0679\u06cc \u0645\u0639\u06cc\u0627\u0631\u0627\u062a \u0642\u0627\u0626\u0645 \u06a9\u06cc\u06d2 \u06c1\u06cc\u06ba:"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ISO 13482"}),": \u0630\u0627\u062a\u06cc \u062f\u06cc\u06a9\u06be \u0628\u06be\u0627\u0644 \u0648\u0627\u0644\u06d2 \u0631\u0648\u0628\u0648\u0679\u0633 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0633\u06cc\u0641\u0679\u06cc \u06a9\u06cc \u0636\u0631\u0648\u0631\u06cc\u0627\u062a"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ISO 12100"}),": \u0645\u0634\u06cc\u0646\u0631\u06cc \u06a9\u06cc \u0633\u06cc\u0641\u0679\u06cc \u06a9\u06d2 \u0627\u0635\u0648\u0644 \u0628\u0631\u0627\u0626\u06d2 \u0631\u0633\u06a9 \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ISO 10218"}),": \u0635\u0646\u0639\u062a\u06cc \u0631\u0648\u0628\u0648\u0679\u0633 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0633\u06cc\u0641\u0679\u06cc \u06a9\u06cc \u0636\u0631\u0648\u0631\u06cc\u0627\u062a"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ANSI/RIA R15.06"}),": \u0635\u0646\u0639\u062a\u06cc \u0631\u0648\u0628\u0648\u0679\u0633 \u0627\u0648\u0631 \u0631\u0648\u0628\u0648\u0679 \u0633\u0633\u0679\u0645\u0632 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0627\u0645\u0631\u06cc\u06a9\u06cc \u0642\u0648\u0645\u06cc \u0645\u0639\u06cc\u0627\u0631"]}),"\n"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    A[\u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0645\u06cc\u06ba \u0633\u06cc\u0641\u0679\u06cc \u0645\u0639\u06cc\u0627\u0631\u0627\u062a] --\x3e B[ISO 13482 - \u0630\u0627\u062a\u06cc \u062f\u06cc\u06a9\u06be \u0628\u06be\u0627\u0644 \u0648\u0627\u0644\u06d2 \u0631\u0648\u0628\u0648\u0679\u0633]\n    A --\x3e C[ISO 12100 - \u0631\u0633\u06a9 \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1]\n    A --\x3e D[ISO 10218 - \u0635\u0646\u0639\u062a\u06cc \u0631\u0648\u0628\u0648\u0679\u0633]\n    A --\x3e E[ANSI/RIA R15.06 - \u0635\u0646\u0639\u062a\u06cc \u0645\u0639\u06cc\u0627\u0631\u0627\u062a]\n\n    B --\x3e B1[\u0627\u0646\u0633\u0627\u0646\u06cc \u0628\u0627\u062a \u0686\u06cc\u062a \u06a9\u06cc \u0633\u06cc\u0641\u0679\u06cc]\n    B --\x3e B2[\u0631\u0627\u0632\u062f\u0627\u0631\u06cc \u06a9\u06cc \u062d\u0641\u0627\u0638\u062a]\n    B --\x3e B3[\u0627\u06cc\u0631\u06af\u0648\u0646\u0648\u0645\u06a9 \u0688\u06cc\u0632\u0627\u0626\u0646]\n\n    C --\x3e C1[\u0631\u0633\u06a9 \u06a9\u06cc \u0634\u0646\u0627\u062e\u062a]\n    C --\x3e C2[\u0631\u0633\u06a9 \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1]\n    C --\x3e C3[\u0631\u0633\u06a9 \u06a9\u06cc \u06a9\u0645\u06cc]\n\n    D --\x3e D1[\u062c\u0633\u0645\u0627\u0646\u06cc \u0633\u06cc\u0641\u0679\u06cc]\n    D --\x3e D2[\u0627\u06cc\u0645\u0631\u062c\u0646\u0633\u06cc \u0627\u0633\u0679\u0627\u067e\u0633]\n    D --\x3e D3[\u0645\u062d\u0641\u0648\u0638 \u062d\u0631\u06a9\u062a]\n\n    E --\x3e E1[\u0622\u067e\u0631\u06cc\u0679\u0631 \u0633\u06cc\u0641\u0679\u06cc]\n    E --\x3e E2[\u0645\u0627\u062d\u0648\u0644\u06cc\u0627\u062a\u06cc \u0633\u06cc\u0641\u0679\u06cc]\n    E --\x3e E3[\u0633\u0633\u0679\u0645 \u0633\u06cc\u0641\u0679\u06cc]\n"})}),(0,i.jsx)(n.h3,{id:"\u0631\u0633\u06a9-\u062c\u0627\u0626\u0632\u06c1-\u06a9\u06d2-\u0641\u0631\u06cc\u0645-\u0648\u0631\u06a9\u0633",children:"\u0631\u0633\u06a9 \u062c\u0627\u0626\u0632\u06c1 \u06a9\u06d2 \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9\u0633"}),(0,i.jsx)(n.p,{children:"\u0645\u0648\u062b\u0631 \u0633\u06cc\u0641\u0679\u06cc \u067e\u0631\u0648\u0679\u0648\u06a9\u0648\u0644\u0632 \u06a9\u0627 \u0622\u063a\u0627\u0632 \u062c\u0627\u0645\u0639 \u0631\u0633\u06a9 \u062c\u0627\u0626\u0632\u06d2 \u0633\u06d2 \u06c1\u0648\u062a\u0627 \u06c1\u06d2\u06d4 \u0627\u0633 \u0645\u06cc\u06ba \u0645\u0645\u06a9\u0646\u06c1 \u062e\u0637\u0631\u0627\u062a \u06a9\u06cc \u0634\u0646\u0627\u062e\u062a\u060c \u0627\u0646 \u06a9\u06d2 \u0627\u0645\u06a9\u0627\u0646 \u0627\u0648\u0631 \u0634\u062f\u062a \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1\u060c \u0627\u0648\u0631 \u0645\u0646\u0627\u0633\u0628 \u06a9\u0645\u06cc \u06a9\u06cc \u062d\u06a9\u0645\u062a \u0639\u0645\u0644\u06cc\u0648\u06ba \u06a9\u0627 \u0646\u0641\u0627\u0630 \u0634\u0627\u0645\u0644 \u06c1\u06d2\u06d4"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# \u0645\u062b\u0627\u0644: \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0633\u0633\u0679\u0645\u0632 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0631\u0633\u06a9 \u062c\u0627\u0626\u0632\u06c1 \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9\nimport numpy as np\nfrom enum import Enum\n\nclass RiskLevel(Enum):\n    LOW = 1\n    MEDIUM = 2\n    HIGH = 3\n    CRITICAL = 4\n\nclass RiskAssessment:\n    def __init__(self):\n        self.hazards = []\n        self.risk_matrix = np.zeros((4, 4))  # \u0634\u062f\u062a x \u0627\u0645\u06a9\u0627\u0646\n\n    def add_hazard(self, hazard_id, description, severity, probability):\n        """\n        \u0631\u0633\u06a9 \u062c\u0627\u0626\u0632\u06d2 \u0645\u06cc\u06ba \u062e\u0637\u0631\u06c1 \u0634\u0627\u0645\u0644 \u06a9\u0631\u06cc\u06ba\n        \u0634\u062f\u062a: 1-5 \u0633\u06a9\u06cc\u0644 (5 = \u0633\u0628 \u0633\u06d2 \u0632\u06cc\u0627\u062f\u06c1 \u0634\u062f\u06cc\u062f)\n        \u0627\u0645\u06a9\u0627\u0646: 1-5 \u0633\u06a9\u06cc\u0644 (5 = \u0633\u0628 \u0633\u06d2 \u0632\u06cc\u0627\u062f\u06c1 \u0627\u0645\u06a9\u0627\u0646)\n        """\n        risk_score = severity * probability\n\n        if risk_score <= 4:\n            risk_level = RiskLevel.LOW\n        elif risk_score <= 8:\n            risk_level = RiskLevel.MEDIUM\n        elif risk_score <= 15:\n            risk_level = RiskLevel.HIGH\n        else:\n            risk_level = RiskLevel.CRITICAL\n\n        hazard = {\n            \'id\': hazard_id,\n            \'description\': description,\n            \'severity\': severity,\n            \'probability\': probability,\n            \'risk_score\': risk_score,\n            \'risk_level\': risk_level,\n            \'mitigation_strategies\': []\n        }\n\n        self.hazards.append(hazard)\n        return hazard\n\n    def evaluate_risk_matrix(self):\n        """\n        \u0631\u0633\u06a9 \u0645\u06cc\u0679\u0631\u06a9\u0633 \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1 \u0644\u06cc\u06ba \u0627\u0648\u0631 \u0627\u06c1\u0645 \u0639\u0644\u0627\u0642\u0648\u06ba \u06a9\u06cc \u0634\u0646\u0627\u062e\u062a \u06a9\u0631\u06cc\u06ba\n        """\n        for hazard in self.hazards:\n            severity_idx = hazard[\'severity\'] - 1\n            prob_idx = hazard[\'probability\'] - 1\n            self.risk_matrix[severity_idx][prob_idx] += 1\n\n    def get_mitigation_recommendations(self):\n        """\n        \u0631\u0633\u06a9 \u06a9\u06cc \u0633\u0637\u062d\u0648\u06ba \u06a9\u06cc \u0628\u0646\u06cc\u0627\u062f \u067e\u0631 \u06a9\u0645\u06cc \u06a9\u06cc \u0633\u0641\u0627\u0631\u0634\u0627\u062a \u062a\u06cc\u0627\u0631 \u06a9\u0631\u06cc\u06ba\n        """\n        recommendations = {\n            RiskLevel.LOW: ["\u0628\u0627\u0642\u0627\u0639\u062f\u06c1 \u0645\u0627\u0646\u06cc\u0679\u0631 \u06a9\u0631\u06cc\u06ba", "\u0628\u0646\u06cc\u0627\u062f\u06cc \u062f\u0633\u062a\u0627\u0648\u06cc\u0632\u0627\u062a"],\n            RiskLevel.MEDIUM: ["\u0633\u06cc\u0641\u0679\u06cc \u0627\u0642\u062f\u0627\u0645\u0627\u062a \u0646\u0627\u0641\u0630 \u06a9\u0631\u06cc\u06ba", "\u0628\u0627\u0642\u0627\u0639\u062f\u06c1 \u0679\u06cc\u0633\u0679\u0646\u06af", "\u0635\u0627\u0631\u0641 \u062a\u0631\u0628\u06cc\u062a"],\n            RiskLevel.HIGH: ["\u0627\u06af\u0631 \u0645\u0645\u06a9\u0646 \u06c1\u0648 \u062a\u0648 \u062f\u0648\u0628\u0627\u0631\u06c1 \u0688\u06cc\u0632\u0627\u0626\u0646 \u06a9\u0631\u06cc\u06ba", "\u06a9\u0626\u06cc \u0633\u06cc\u0641\u0679\u06cc \u0644\u06cc\u0626\u0631\u0632", "\u0628\u0627\u0642\u0627\u0639\u062f\u06c1 \u0645\u0627\u0646\u06cc\u0679\u0631\u0646\u06af"],\n            RiskLevel.CRITICAL: ["\u0622\u06af\u06d2 \u0646\u06c1 \u0628\u0691\u06be\u06cc\u06ba", " fundamental redesign required", "\u0645\u0627\u06c1\u0631 \u0645\u0634\u0648\u0631\u06c1"]\n        }\n\n        return recommendations\n\n# \u0645\u062b\u0627\u0644 \u06a9\u0627 \u0627\u0633\u062a\u0639\u0645\u0627\u0644\ndef assess_robot_safety():\n    assessment = RiskAssessment()\n\n    # \u0639\u0627\u0645 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u062e\u0637\u0631\u0627\u062a \u0634\u0627\u0645\u0644 \u06a9\u0631\u06cc\u06ba\n    assessment.add_hazard(\n        "H001",\n        "\u0627\u0646\u0633\u0627\u0646\u0648\u06ba \u06a9\u06d2 \u0633\u0627\u062a\u06be \u062c\u0633\u0645\u0627\u0646\u06cc \u0679\u06a9\u0631\u0627\u0624",\n        severity=5,\n        probability=3\n    )\n\n    assessment.add_hazard(\n        "H002",\n        "\u0627\u06c1\u0645 \u0622\u067e\u0631\u06cc\u0634\u0646 \u06a9\u06d2 \u062f\u0648\u0631\u0627\u0646 \u0633\u0633\u0679\u0645 \u0646\u0627\u06a9\u0627\u0645\u06cc",\n        severity=4,\n        probability=2\n    )\n\n    assessment.add_hazard(\n        "H003",\n        "\u0688\u06cc\u0679\u0627 \u0631\u0627\u0632\u062f\u0627\u0631\u06cc \u06a9\u06cc \u062e\u0644\u0627\u0641 \u0648\u0631\u0632\u06cc",\n        severity=3,\n        probability=2\n    )\n\n    assessment.evaluate_risk_matrix()\n    return assessment\n'})}),(0,i.jsx)(n.h3,{id:"\u0633\u06cc\u0641\u0679\u06cc-\u0622\u0631\u06a9\u06cc\u0679\u06cc\u06a9\u0686\u0631-\u0688\u06cc\u0632\u0627\u0626\u0646",children:"\u0633\u06cc\u0641\u0679\u06cc \u0622\u0631\u06a9\u06cc\u0679\u06cc\u06a9\u0686\u0631 \u0688\u06cc\u0632\u0627\u0626\u0646"}),(0,i.jsx)(n.p,{children:"\u0627\u06cc\u06a9 \u0645\u0636\u0628\u0648\u0637 \u0633\u06cc\u0641\u0679\u06cc \u0622\u0631\u06a9\u06cc\u0679\u06cc\u06a9\u0686\u0631 \u0645\u062a\u0639\u062f\u062f \u062a\u062d\u0641\u0638 \u06a9\u06cc \u067e\u0631\u062a\u06cc\u06ba \u0634\u0627\u0645\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2 \u062a\u0627\u06a9\u06c1 \u0646\u0627\u06a9\u0627\u0645\u06cc\u0648\u06ba \u06cc\u0627 \u063a\u06cc\u0631 \u0645\u062a\u0648\u0642\u0639 \u062d\u0627\u0644\u0627\u062a \u06a9\u06d2 \u0648\u062c\u0648\u062f \u0645\u06cc\u06ba \u0628\u06be\u06cc \u0645\u062d\u0641\u0648\u0638 \u0631\u0648\u0628\u0648\u0679 \u0622\u067e\u0631\u06cc\u0634\u0646 \u06a9\u0648 \u06cc\u0642\u06cc\u0646\u06cc \u0628\u0646\u0627\u06cc\u0627 \u062c\u0627 \u0633\u06a9\u06d2\u06d4"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# \u0645\u062b\u0627\u0644: \u06c1\u06cc\u0648\u0645\u0646\u0648\u0627\u0626\u0688 \u0631\u0648\u0628\u0648\u0679 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0633\u06cc\u0641\u0679\u06cc \u0622\u0631\u06a9\u06cc\u0679\u06cc\u06a9\u0686\u0631\nimport threading\nimport time\nfrom dataclasses import dataclass\nfrom typing import List, Optional\n\n@dataclass\nclass SafetyConstraint:\n    name: str\n    min_value: float\n    max_value: float\n    current_value: float\n    enabled: bool = True\n\nclass SafetyMonitor:\n    def __init__(self):\n        self.constraints = []\n        self.emergency_stop = False\n        self.monitoring_thread = None\n        self.is_monitoring = False\n\n    def add_constraint(self, name: str, min_val: float, max_val: float):\n        """\u0646\u06af\u0631\u0627\u0646\u06cc \u06a9\u06d2 \u0644\u06cc\u06d2 \u0627\u06cc\u06a9 \u0633\u06cc\u0641\u0679\u06cc \u06a9\u0646\u0679\u0631\u06cc\u0628\u06cc\u0648\u0679 \u0634\u0627\u0645\u0644 \u06a9\u0631\u06cc\u06ba"""\n        constraint = SafetyConstraint(name, min_val, max_val, 0.0)\n        self.constraints.append(constraint)\n\n    def update_constraint(self, name: str, value: float):\n        """\u06a9\u0646\u0679\u0631\u06cc\u0628\u06cc\u0648\u0679 \u0648\u06cc\u0644\u06cc\u0648 \u0627\u067e \u0688\u06cc\u0679 \u06a9\u0631\u06cc\u06ba"""\n        for constraint in self.constraints:\n            if constraint.name == name:\n                constraint.current_value = value\n                break\n\n    def check_constraints(self) -> List[str]:\n        """\u062a\u0645\u0627\u0645 \u06a9\u0646\u0679\u0631\u06cc\u0628\u06cc\u0648\u0679\u0633 \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba \u0627\u0648\u0631 \u062e\u0644\u0627\u0641 \u0648\u0631\u0632\u06cc\u0627\u06ba \u0644\u0648\u0679\u0627\u0626\u06cc\u06ba"""\n        violations = []\n        for constraint in self.constraints:\n            if constraint.enabled:\n                if constraint.current_value < constraint.min_value or \\\n                   constraint.current_value > constraint.max_value:\n                    violations.append(constraint.name)\n        return violations\n\n    def start_monitoring(self):\n        """\u0645\u0633\u0644\u0633\u0644 \u0633\u06cc\u0641\u0679\u06cc \u0645\u0627\u0646\u06cc\u0679\u0631\u0646\u06af \u0634\u0631\u0648\u0639 \u06a9\u0631\u06cc\u06ba"""\n        self.is_monitoring = True\n        self.monitoring_thread = threading.Thread(target=self._monitor_loop)\n        self.monitoring_thread.start()\n\n    def stop_monitoring(self):\n        """\u0633\u06cc\u0641\u0679\u06cc \u0645\u0627\u0646\u06cc\u0679\u0631\u0646\u06af \u0628\u0646\u062f \u06a9\u0631\u06cc\u06ba"""\n        self.is_monitoring = False\n        if self.monitoring_thread:\n            self.monitoring_thread.join()\n\n    def _monitor_loop(self):\n        """\u0627\u0646\u062f\u0631\u0648\u0646\u06cc \u0645\u0627\u0646\u06cc\u0679\u0631\u0646\u06af \u0644\u0648\u067e"""\n        while self.is_monitoring:\n            violations = self.check_constraints()\n            if violations:\n                print(f"\u0633\u06cc\u0641\u0679\u06cc \u062e\u0644\u0627\u0641 \u0648\u0631\u0632\u06cc\u0627\u06ba \u062f\u0631\u06cc\u0627\u0641\u062a \u06c1\u0648\u0626\u06cc\u06ba: {violations}")\n                self.trigger_emergency_stop()\n\n            time.sleep(0.01)  # 100 Hz \u0645\u0627\u0646\u06cc\u0679\u0631\u0646\u06af\n\n    def trigger_emergency_stop(self):\n        """\u0627\u06cc\u0645\u0631\u062c\u0646\u0633\u06cc \u0627\u0633\u0679\u0627\u067e \u0686\u0644\u0627\u0626\u06cc\u06ba \u0627\u0648\u0631 \u062d\u0627\u062f\u062b\u06c1 \u0631\u06cc\u06a9\u0627\u0631\u0688 \u06a9\u0631\u06cc\u06ba"""\n        self.emergency_stop = True\n        print("\u0627\u06cc\u0645\u0631\u062c\u0646\u0633\u06cc \u0627\u0633\u0679\u0627\u067e \u0641\u0639\u0627\u0644!")\n        # \u062d\u0642\u06cc\u0642\u06cc \u0646\u0641\u0627\u0630 \u0645\u06cc\u06ba\u060c \u0631\u0648\u0628\u0648\u0679 \u06a9\u0648 \u0627\u0633\u0679\u0627\u067e \u06a9\u0645\u0627\u0646\u0688\u0632 \u0628\u06be\u06cc\u062c\u06cc\u06ba \u06af\u0627\n\nclass SafetyController:\n    def __init__(self):\n        self.safety_monitor = SafetyMonitor()\n        self.initialize_constraints()\n\n    def initialize_constraints(self):\n        """\u062a\u0645\u0627\u0645 \u0633\u06cc\u0641\u0679\u06cc \u06a9\u0646\u0679\u0631\u06cc\u0628\u06cc\u0648\u0679\u0633 \u0634\u0631\u0648\u0639 \u06a9\u0631\u06cc\u06ba"""\n        # \u062c\u0648\u0627\u0626\u0646\u0679 \u067e\u0648\u0632\u06cc\u0634\u0646 \u06a9\u06cc \u062d\u062f\u06cc\u06ba\n        for i in range(12):  # 12 \u062c\u0648\u0627\u0626\u0646\u0679\u0633 \u06a9\u0627 \u0641\u0631\u0636\n            self.safety_monitor.add_constraint(\n                f"joint_{i}_position",\n                min_val=-2.5,\n                max_val=2.5\n            )\n\n        # \u062c\u0648\u0627\u0626\u0646\u0679 \u0648\u06cc\u0644\u0648\u0633\u06cc\u0679\u06cc \u06a9\u06cc \u062d\u062f\u06cc\u06ba\n        for i in range(12):\n            self.safety_monitor.add_constraint(\n                f"joint_{i}_velocity",\n                min_val=-5.0,\n                max_val=5.0\n            )\n\n        # \u062c\u0648\u0627\u0626\u0646\u0679 \u0679\u0648\u0631\u06a9 \u06a9\u06cc \u062d\u062f\u06cc\u06ba\n        for i in range(12):\n            self.safety_monitor.add_constraint(\n                f"joint_{i}_torque",\n                min_val=-100.0,\n                max_val=100.0\n            )\n\n        # \u0627\u06cc\u0646\u0688 \u0627\u06cc\u0641\u06cc\u06a9\u0679\u0631 \u067e\u0648\u0632\u06cc\u0634\u0646 \u06a9\u06cc \u062d\u062f\u06cc\u06ba (\u0648\u0631\u06a9 \u0627\u0633\u067e\u06cc\u0633)\n        self.safety_monitor.add_constraint("ee_x_position", -1.0, 1.0)\n        self.safety_monitor.add_constraint("ee_y_position", -1.0, 1.0)\n        self.safety_monitor.add_constraint("ee_z_position", 0.1, 2.0)\n\n    def check_safety(self, joint_positions, joint_velocities, joint_torques, ee_position):\n        """\u062f\u06cc \u06af\u0626\u06cc \u0631\u0648\u0628\u0648\u0679 \u0627\u0633\u0679\u06cc\u0679 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0633\u06cc\u0641\u0679\u06cc \u06a9\u0646\u0679\u0631\u06cc\u0628\u06cc\u0648\u0679\u0633 \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba"""\n        # \u06a9\u0646\u0679\u0631\u06cc\u0628\u06cc\u0648\u0679 \u0648\u06cc\u0644\u06cc\u0648\u0632 \u0627\u067e \u0688\u06cc\u0679 \u06a9\u0631\u06cc\u06ba\n        for i, pos in enumerate(joint_positions):\n            self.safety_monitor.update_constraint(f"joint_{i}_position", pos)\n\n        for i, vel in enumerate(joint_velocities):\n            self.safety_monitor.update_constraint(f"joint_{i}_velocity", vel)\n\n        for i, torque in enumerate(joint_torques):\n            self.safety_monitor.update_constraint(f"joint_{i}_torque", torque)\n\n        self.safety_monitor.update_constraint("ee_x_position", ee_position[0])\n        self.safety_monitor.update_constraint("ee_y_position", ee_position[1])\n        self.safety_monitor.update_constraint("ee_z_position", ee_position[2])\n\n        # \u062e\u0644\u0627\u0641 \u0648\u0631\u0632\u06cc\u0648\u06ba \u06a9\u06d2 \u0644\u06cc\u06d2 \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba\n        violations = self.safety_monitor.check_constraints()\n        return len(violations) == 0, violations\n\n# \u0645\u062b\u0627\u0644 \u06a9\u0627 \u0627\u0633\u062a\u0639\u0645\u0627\u0644\ndef main():\n    safety_controller = SafetyController()\n    safety_controller.safety_monitor.start_monitoring()\n\n    # \u0631\u0648\u0628\u0648\u0679 \u0627\u0633\u0679\u06cc\u0679 \u0686\u06cc\u06a9\u0646\u06af \u06a9\u06cc \u0634\u0628\u06cc\u06c1 \u0633\u0627\u0632\u06cc\n    joint_positions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n    joint_velocities = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.11, 0.12]\n    joint_torques = [5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0]\n    ee_position = [0.5, 0.3, 0.8]\n\n    is_safe, violations = safety_controller.check_safety(\n        joint_positions, joint_velocities, joint_torques, ee_position\n    )\n\n    if is_safe:\n        print("\u0631\u0648\u0628\u0648\u0679 \u0627\u0633\u0679\u06cc\u0679 \u0645\u062d\u0641\u0648\u0638 \u06c1\u06d2")\n    else:\n        print(f"\u0631\u0648\u0628\u0648\u0679 \u0627\u0633\u0679\u06cc\u0679 \u063a\u06cc\u0631 \u0645\u062d\u0641\u0648\u0638 - \u062e\u0644\u0627\u0641 \u0648\u0631\u0632\u06cc\u0627\u06ba: {violations}")\n\n    # \u0635\u0627\u0641 \u06a9\u0631\u06cc\u06ba\n    safety_controller.safety_monitor.stop_monitoring()\n\nif __name__ == "__main__":\n    main()\n'})}),(0,i.jsx)(n.h2,{id:"\u0631\u0648\u0628\u0648\u0679\u06a9\u0633-\u0645\u06cc\u06ba-\u0627\u062e\u0644\u0627\u0642\u06cc-\u0641\u0631\u06cc\u0645-\u0648\u0631\u06a9\u0633",children:"\u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0645\u06cc\u06ba \u0627\u062e\u0644\u0627\u0642\u06cc \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9\u0633"}),(0,i.jsx)(n.p,{children:"\u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0645\u06cc\u06ba \u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a \u0688\u06cc\u0632\u0627\u0626\u0646\u060c \u062a\u0631\u0642\u06cc\u060c \u0627\u0648\u0631 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0633\u0633\u0679\u0645\u0632 \u06a9\u06d2 \u0627\u062a\u0627\u0631\u0646\u06d2 \u06a9\u06d2 \u0627\u0635\u0648\u0644\u0648\u06ba \u0627\u0648\u0631 \u0627\u0642\u062f\u0627\u0631 \u06a9\u0648 \u062d\u0644 \u06a9\u0631\u062a\u06cc \u06c1\u06d2 \u062c\u0646 \u06a9\u06cc \u06c1\u062f\u0627\u06cc\u062a \u06a9\u0631\u0646\u06cc \u0686\u0627\u06c1\u06cc\u06d2\u06d4 \u062c\u06cc\u0633\u06d2 \u062c\u06cc\u0633\u06d2 \u0631\u0648\u0628\u0648\u0679\u0633 \u0632\u06cc\u0627\u062f\u06c1 \u062e\u0648\u062f \u0645\u062e\u062a\u0627\u0631 \u0627\u0648\u0631 \u0645\u0639\u0627\u0634\u0631\u06d2 \u0645\u06cc\u06ba \u0645\u0631\u0628\u0648\u0637 \u06c1\u0648\u062a\u06d2 \u062c\u0627\u062a\u06d2 \u06c1\u06cc\u06ba\u060c \u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a \u06a9\u0627 \u062e\u06cc\u0627\u0644 \u0627\u0646\u062a\u06c1\u0627\u0626\u06cc \u0627\u06c1\u0645 \u06c1\u0648 \u062c\u0627\u062a\u0627 \u06c1\u06d2\u06d4"}),(0,i.jsx)(n.h3,{id:"\u0627\u06cc\u0632\u06cc\u0645\u0648\u0648-\u06a9\u06d2-\u0631\u0648\u0628\u0648\u0679\u06a9\u0633-\u06a9\u06d2-\u0642\u0648\u0627\u0646\u06cc\u0646",children:"\u0627\u06cc\u0632\u06cc\u0645\u0648\u0648 \u06a9\u06d2 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u06a9\u06d2 \u0642\u0648\u0627\u0646\u06cc\u0646"}),(0,i.jsx)(n.p,{children:"\u0622\u0626\u0632\u06a9 \u0627\u06cc\u0632\u06cc\u0645\u0648\u0648 \u06a9\u06d2 \u062a\u06cc\u0646 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u06a9\u06d2 \u0642\u0648\u0627\u0646\u06cc\u0646\u060c \u062c\u0628\u06a9\u06c1 \u062e\u06cc\u0627\u0644\u06cc\u060c \u0631\u0648\u0628\u0648\u0679 \u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a \u06a9\u06d2 \u0628\u0627\u0631\u06d2 \u0645\u06cc\u06ba \u0633\u0648\u0686\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0627\u06cc\u06a9 \u0628\u0646\u06cc\u0627\u062f\u06cc \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9 \u0641\u0631\u0627\u06c1\u0645 \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba:"}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"\u0627\u06cc\u06a9 \u0631\u0648\u0628\u0648\u0679 \u0627\u06cc\u06a9 \u0627\u0646\u0633\u0627\u0646 \u06a9\u0648 \u0646\u0642\u0635\u0627\u0646 \u0646\u06c1\u06cc\u06ba \u067e\u06c1\u0646\u0686\u0627 \u0633\u06a9\u062a\u0627 \u06cc\u0627\u060c \u06a9\u0627\u0631\u0631\u0648\u0627\u0626\u06cc \u0646\u06c1 \u06a9\u0631 \u06a9\u06d2\u060c \u0627\u06cc\u06a9 \u0627\u0646\u0633\u0627\u0646 \u06a9\u0648 \u0646\u0642\u0635\u0627\u0646 \u067e\u06c1\u0646\u0686\u0646\u06d2 \u0633\u06d2 \u0646\u06c1\u06cc\u06ba \u0631\u0648\u06a9 \u0633\u06a9\u062a\u0627"}),"\n",(0,i.jsx)(n.li,{children:"\u0627\u06cc\u06a9 \u0631\u0648\u0628\u0648\u0679 \u06a9\u0648 \u0627\u0646\u0633\u0627\u0646\u0648\u06ba \u06a9\u06d2 \u0630\u0631\u06cc\u0639\u06d2 \u062f\u06cc\u06d2 \u06af\u0626\u06d2 \u062d\u06a9\u0645 \u0645\u0627\u0646\u062a\u06d2 \u06c1\u0648\u0626\u06d2\u060c \u0633\u0648\u0627\u0626\u06d2 \u0627\u0646 \u062d\u06a9\u0645\u0648\u06ba \u06a9\u06d2 \u062c\u06c1\u0627\u06ba \u0627\u0633 \u06a9\u0627 \u062a\u0646\u0627\u0632\u0639\u06c1 \u067e\u06c1\u0644\u06d2 \u0642\u0627\u0646\u0648\u0646 \u0633\u06d2 \u06c1\u0648"}),"\n",(0,i.jsx)(n.li,{children:"\u0627\u06cc\u06a9 \u0631\u0648\u0628\u0648\u0679 \u0627\u067e\u0646\u06d2 \u0648\u062c\u0648\u062f \u06a9\u06cc \u062d\u0641\u0627\u0638\u062a \u06a9\u0631\u0646\u0627 \u0686\u0627\u06c1\u06cc\u06d2 \u062c\u0628 \u062a\u06a9 \u06a9\u06c1 \u0627\u0633 \u06a9\u06cc \u062d\u0641\u0627\u0638\u062a \u067e\u06c1\u0644\u06d2 \u06cc\u0627 \u062f\u0648\u0633\u0631\u06d2 \u0642\u0627\u0646\u0648\u0646 \u06a9\u06d2 \u062a\u0646\u0627\u0632\u0639\u06d2 \u0645\u06cc\u06ba \u0646\u06c1 \u06c1\u0648"}),"\n"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    A[\u0627\u06cc\u0632\u06cc\u0645\u0648\u0648 \u06a9\u06d2 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u06a9\u06d2 \u0642\u0648\u0627\u0646\u06cc\u0646] --\x3e B[\u067e\u06c1\u0644\u0627 \u0642\u0627\u0646\u0648\u0646 - \u0627\u0646\u0633\u0627\u0646\u06cc \u0633\u06cc\u0641\u0679\u06cc]\n    A --\x3e C[\u062f\u0648\u0633\u0631\u0627 \u0642\u0627\u0646\u0648\u0646 - \u0627\u0646\u0633\u0627\u0646\u0648\u06ba \u06a9\u06cc \u0627\u0637\u0627\u0639\u062a]\n    A --\x3e D[\u062a\u06cc\u0633\u0631\u0627 \u0642\u0627\u0646\u0648\u0646 - \u062e\u0648\u062f \u06a9\u06cc \u062d\u0641\u0627\u0638\u062a]\n\n    B --\x3e B1[\u0627\u0646\u0633\u0627\u0646\u0648\u06ba \u06a9\u0648 \u0646\u0642\u0635\u0627\u0646 \u0633\u06d2 \u0628\u0686\u0627\u0626\u06cc\u06ba]\n    B --\x3e B2[\u06a9\u0627\u0631\u0631\u0648\u0627\u0626\u06cc \u0646\u06c1 \u06a9\u0631 \u06a9\u06d2 \u0646\u0642\u0635\u0627\u0646 \u0633\u06d2 \u0628\u0686\u0627\u0626\u06cc\u06ba]\n\n    C --\x3e C1[\u0627\u0646\u0633\u0627\u0646\u06cc \u062d\u06a9\u0645 \u0645\u0627\u0646\u06cc\u06ba]\n    C --\x3e C2[\u0627\u0633\u062a\u062b\u0646\u06cc\u0670: \u067e\u06c1\u0644\u06d2 \u0642\u0627\u0646\u0648\u0646 \u06a9\u06d2 \u0633\u0627\u062a\u06be \u062a\u0646\u0627\u0632\u0639\u06c1]\n\n    D --\x3e D1[\u0627\u067e\u0646\u06d2 \u0648\u062c\u0648\u062f \u06a9\u06cc \u062d\u0641\u0627\u0638\u062a \u06a9\u0631\u06cc\u06ba]\n    D --\x3e D2[\u0627\u0633\u062a\u062b\u0646\u06cc\u0670: \u067e\u06c1\u0644\u06d2 \u06cc\u0627 \u062f\u0648\u0633\u0631\u06d2 \u0642\u0627\u0646\u0648\u0646 \u06a9\u06d2 \u0633\u0627\u062a\u06be \u062a\u0646\u0627\u0632\u0639\u06c1]\n"})}),(0,i.jsx)(n.h3,{id:"\u062c\u062f\u06cc\u062f-\u0627\u062e\u0644\u0627\u0642\u06cc-\u0641\u0631\u06cc\u0645-\u0648\u0631\u06a9\u0633",children:"\u062c\u062f\u06cc\u062f \u0627\u062e\u0644\u0627\u0642\u06cc \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9\u0633"}),(0,i.jsx)(n.p,{children:"\u0631\u0648\u0628\u0648\u0679 \u0627\u062e\u0644\u0627\u0642\u06cc\u0627\u062a \u0645\u06cc\u06ba \u0645\u0639\u0627\u0635\u0631 \u0646\u0642\u0637\u06c1 \u0646\u0638\u0631 \u0627\u06cc\u0632\u06cc\u0645\u0648\u0648 \u06a9\u06d2 \u0642\u0648\u0627\u0646\u06cc\u0646 \u0633\u06d2 \u0622\u06af\u06d2 \u0628\u0691\u06be \u06af\u06cc\u0627 \u06c1\u06d2 \u062a\u0627\u06a9\u06c1 \u062c\u062f\u06cc\u062f AI \u0627\u0648\u0631 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u06a9\u06cc \u067e\u06cc\u0686\u06cc\u062f\u06af\u06cc\u0648\u06ba \u06a9\u0648 \u062d\u0644 \u06a9\u06cc\u0627 \u062c\u0627 \u0633\u06a9\u06d2:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# \u0645\u062b\u0627\u0644: \u0631\u0648\u0628\u0648\u0679\u0633 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0627\u062e\u0644\u0627\u0642\u06cc \u0641\u06cc\u0635\u0644\u06c1 \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Any\nimport json\n\nclass EthicalPrinciple(Enum):\n    BENEFICENCE = "beneficence"  # \u0627\u0686\u06be\u0627\u0626\u06cc \u06a9\u0631\u06cc\u06ba\n    NON_MALEFICENCE = "non_maleficence"  # \u0646\u0642\u0635\u0627\u0646 \u0646\u06c1 \u06a9\u0631\u06cc\u06ba\n    AUTONOMY = "autonomy"  # \u062e\u0648\u062f \u0645\u062e\u062a\u0627\u0631\u06cc \u06a9\u0627 \u0627\u062d\u062a\u0631\u0627\u0645\n    JUSTICE = "justice"  # \u0627\u0646\u0635\u0627\u0641 \u0627\u0648\u0631 \u0628\u0631\u0627\u0628\u0631\u06cc\n    VERACITY = "veracity"  # \u0633\u0686\u0627\u0626\u06cc\n    FIDELITY = "fidelity"  # \u0648\u0641\u0627\u062f\u0627\u0631\u06cc \u0627\u0648\u0631 \u0648\u0639\u062f\u06c1 \u0646\u0628\u06be\u0627\u0646\u0627\n\n@dataclass\nclass EthicalDecision:\n    action: str\n    principle: EthicalPrinciple\n    weight: float  # 0.0 \u0633\u06d2 1.0\n    justification: str\n\nclass EthicalFramework:\n    def __init__(self):\n        self.principles = {\n            EthicalPrinciple.BENEFICENCE: 1.0,\n            EthicalPrinciple.NON_MALEFICENCE: 1.0,\n            EthicalPrinciple.AUTONOMY: 0.8,\n            EthicalPrinciple.JUSTICE: 0.9,\n            EthicalPrinciple.VERACITY: 0.7,\n            EthicalPrinciple.FIDELITY: 0.6\n        }\n\n        self.decision_log = []\n\n    def evaluate_action(self, action: str, context: Dict[str, Any]) -> List[EthicalDecision]:\n        """\n        \u0627\u062e\u0644\u0627\u0642\u06cc \u0627\u0635\u0648\u0644\u0648\u06ba \u06a9\u06d2 \u062e\u0644\u0627\u0641 \u0627\u06cc\u06a9 \u0627\u06cc\u06a9\u0634\u0646 \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1 \u0644\u06cc\u06ba\n        """\n        decisions = []\n\n        # \u0646\u0642\u0635\u0627\u0646 \u0633\u06d2 \u0628\u0686\u0627\u0624 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba (non-maleficence)\n        harm_risk = self._assess_harm_risk(action, context)\n        if harm_risk > 0.5:\n            decisions.append(EthicalDecision(\n                action=action,\n                principle=EthicalPrinciple.NON_MALEFICENCE,\n                weight=1.0 - harm_risk,\n                justification=f"\u0627\u06cc\u06a9\u0634\u0646 \u0645\u06cc\u06ba {harm_risk:.2f} \u0646\u0642\u0635\u0627\u0646 \u06a9\u0627 \u062e\u0637\u0631\u06c1 \u06c1\u06d2"\n            ))\n\n        # \u0641\u0627\u0626\u062f\u06c1 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba (beneficence)\n        benefit = self._assess_benefit(action, context)\n        if benefit > 0.3:\n            decisions.append(EthicalDecision(\n                action=action,\n                principle=EthicalPrinciple.BENEFICENCE,\n                weight=benefit,\n                justification=f"\u0627\u06cc\u06a9\u0634\u0646 {benefit:.2f} \u0641\u0627\u0626\u062f\u06c1 \u0641\u0631\u0627\u06c1\u0645 \u06a9\u0631\u062a\u0627 \u06c1\u06d2"\n            ))\n\n        # \u062e\u0648\u062f \u0645\u062e\u062a\u0627\u0631\u06cc \u06a9\u0627 \u0627\u062d\u062a\u0631\u0627\u0645 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba\n        autonomy_impact = self._assess_autonomy_impact(action, context)\n        if abs(autonomy_impact) > 0.2:\n            weight = abs(autonomy_impact)\n            principle = EthicalPrinciple.AUTONOMY if autonomy_impact > 0 else None\n            if principle:\n                decisions.append(EthicalDecision(\n                    action=action,\n                    principle=principle,\n                    weight=weight,\n                    justification=f"\u0627\u06cc\u06a9\u0634\u0646 \u0627\u0646\u0633\u0627\u0646\u06cc \u062e\u0648\u062f \u0645\u062e\u062a\u0627\u0631\u06cc \u06a9\u0648 {autonomy_impact:.2f} \u0633\u06d2 \u0645\u062a\u0627\u062b\u0631 \u06a9\u0631\u062a\u0627 \u06c1\u06d2"\n                ))\n\n        # \u0627\u0646\u0635\u0627\u0641 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba\n        fairness_impact = self._assess_fairness(action, context)\n        if abs(fairness_impact) > 0.3:\n            weight = abs(fairness_impact)\n            principle = EthicalPrinciple.JUSTICE if fairness_impact > 0 else None\n            if principle:\n                decisions.append(EthicalDecision(\n                    action=action,\n                    principle=principle,\n                    weight=weight,\n                    justification=f"\u0627\u06cc\u06a9\u0634\u0646 \u0627\u0646\u0635\u0627\u0641 \u06a9\u0648 {fairness_impact:.2f} \u0633\u06d2 \u0645\u062a\u0627\u062b\u0631 \u06a9\u0631\u062a\u0627 \u06c1\u06d2"\n                ))\n\n        self.decision_log.append({\n            \'action\': action,\n            \'context\': context,\n            \'decisions\': [d.__dict__ for d in decisions],\n            \'timestamp\': time.time()\n        })\n\n        return decisions\n\n    def _assess_harm_risk(self, action: str, context: Dict[str, Any]) -> float:\n        """\u0627\u06cc\u06a9\u0634\u0646 \u0633\u06d2 \u0646\u0642\u0635\u0627\u0646 \u06a9\u0627 \u062e\u0637\u0631\u06c1 \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1 \u0644\u06cc\u06ba"""\n        # \u0627\u06cc\u06a9\u0634\u0646 \u06a9\u06cc \u0642\u0633\u0645 \u06a9\u06cc \u0628\u0646\u06cc\u0627\u062f \u067e\u0631 \u0633\u0627\u062f\u06c1 \u062c\u0627\u0626\u0632\u06c1\n        harm_keywords = [\'push\', \'hit\', \'force\', \'aggressive\', \'dangerous\']\n        risk = sum(1 for keyword in harm_keywords if keyword.lower() in action.lower())\n        return min(risk / 3.0, 1.0)  # 0-1 \u0631\u06cc\u0646\u062c \u0645\u06cc\u06ba \u0646\u0627\u0631\u0645\u0644\u0627\u0626\u0632 \u06a9\u0631\u06cc\u06ba\n\n    def _assess_benefit(self, action: str, context: Dict[str, Any]) -> float:\n        """\u0627\u06cc\u06a9\u0634\u0646 \u06a9\u0627 \u0641\u0627\u0626\u062f\u06c1 \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1 \u0644\u06cc\u06ba"""\n        benefit_keywords = [\'help\', \'assist\', \'support\', \'aid\', \'assist\']\n        benefit = sum(1 for keyword in benefit_keywords if keyword.lower() in action.lower())\n        return min(benefit / 2.0, 1.0)  # 0-1 \u0631\u06cc\u0646\u062c \u0645\u06cc\u06ba \u0646\u0627\u0631\u0645\u0644\u0627\u0626\u0632 \u06a9\u0631\u06cc\u06ba\n\n    def _assess_autonomy_impact(self, action: str, context: Dict[str, Any]) -> float:\n        """\u0627\u0646\u0633\u0627\u0646\u06cc \u062e\u0648\u062f \u0645\u062e\u062a\u0627\u0631\u06cc \u067e\u0631 \u0627\u062b\u0631 \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1 \u0644\u06cc\u06ba"""\n        # \u062e\u0648\u062f \u0645\u062e\u062a\u0627\u0631\u06cc \u06a9\u06cc \u062d\u0645\u0627\u06cc\u062a \u06a9\u0631\u062a\u0627 \u06c1\u06d2 \u062a\u0648 \u0645\u062b\u0628\u062a\u060c \u0627\u0633\u06d2 \u0645\u062d\u062f\u0648\u062f \u06a9\u0631\u062a\u0627 \u06c1\u06d2 \u062a\u0648 \u0645\u0646\u0641\u06cc\n        if \'ask_permission\' in action.lower() or \'request_consent\' in action.lower():\n            return 0.8\n        elif \'override_human\' in action.lower() or \'disregard_human\' in action.lower():\n            return -0.9\n        return 0.0\n\n    def _assess_fairness(self, action: str, context: Dict[str, Any]) -> float:\n        """\u0627\u0646\u0635\u0627\u0641 \u06a9\u0627 \u0627\u062b\u0631 \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1 \u0644\u06cc\u06ba"""\n        # \u0633\u0627\u062f\u06c1 \u0627\u0646\u0635\u0627\u0641 \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1\n        if \'equal_treatment\' in context.get(\'goal\', \'\').lower():\n            return 0.7 if \'equal\' in action.lower() else -0.5\n        return 0.0\n\n    def make_ethical_decision(self, action: str, context: Dict[str, Any]) -> bool:\n        """\n        \u0627\u06cc\u06a9 \u0627\u062e\u0644\u0627\u0642\u06cc \u0641\u06cc\u0635\u0644\u06c1 \u06a9\u0631\u06cc\u06ba \u06a9\u06c1 \u06a9\u06cc\u0627 \u0627\u06cc\u06a9\u0634\u0646 \u06a9\u06d2 \u0633\u0627\u062a\u06be \u0622\u06af\u06d2 \u0628\u0691\u06be\u0646\u0627 \u06c1\u06d2\n        """\n        decisions = self.evaluate_action(action, context)\n\n        if not decisions:\n            return True  # \u06a9\u0648\u0626\u06cc \u0627\u062e\u0644\u0627\u0642\u06cc \u062a\u0634\u0648\u06cc\u0634 \u0646\u06c1\u06cc\u06ba\u060c \u0622\u06af\u06d2 \u0628\u0691\u06be\u06cc\u06ba\n\n        # \u06a9\u0644 \u0627\u062e\u0644\u0627\u0642\u06cc \u0627\u0633\u06a9\u0648\u0631 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba\n        total_score = 0\n        total_weight = 0\n\n        for decision in decisions:\n            weight = self.principles[decision.principle]\n            score = decision.weight if decision.principle in [\n                EthicalPrinciple.BENEFICENCE, EthicalPrinciple.AUTONOMY,\n                EthicalPrinciple.JUSTICE, EthicalPrinciple.VERACITY,\n                EthicalPrinciple.FIDELITY\n            ] else (1 - decision.weight)  # non-maleficence \u06a9\u06d2 \u0644\u06cc\u06d2\u060c \u06a9\u0645 \u062e\u0637\u0631\u06c1 \u0628\u06c1\u062a\u0631 \u06c1\u06d2\n\n            total_score += score * weight\n            total_weight += weight\n\n        if total_weight > 0:\n            avg_score = total_score / total_weight\n            return avg_score > 0.5  # \u0627\u062e\u0644\u0627\u0642\u06cc \u0627\u0633\u06a9\u0648\u0631 > 0.5 \u06c1\u0648\u0646\u06d2 \u067e\u0631 \u0622\u06af\u06d2 \u0628\u0691\u06be\u06cc\u06ba\n        else:\n            return True\n\n# \u0645\u062b\u0627\u0644 \u06a9\u0627 \u0627\u0633\u062a\u0639\u0645\u0627\u0644\ndef ethical_decision_example():\n    framework = EthicalFramework()\n\n    # \u0645\u062e\u062a\u0644\u0641 \u0627\u06cc\u06a9\u0634\u0646\u0632 \u06a9\u06cc \u062c\u0627\u0646\u0686 \u06a9\u0631\u06cc\u06ba\n    actions = [\n        "assist_human_with_task",\n        "push_human_out_of_way",\n        "ask_permission_before_helping",\n        "ignore_human_request_for_help"\n    ]\n\n    context = {\n        "environment": "home",\n        "humans_present": 1,\n        "goal": "assist_with_daily_activities"\n    }\n\n    for action in actions:\n        should_proceed = framework.make_ethical_decision(action, context)\n        print(f"\u0627\u06cc\u06a9\u0634\u0646: {action} - \u0622\u06af\u06d2 \u0628\u0691\u06be\u06cc\u06ba: {should_proceed}")\n\n    return framework\n'})}),(0,i.jsx)(n.h2,{id:"\u0631\u0627\u0632\u062f\u0627\u0631\u06cc-\u0627\u0648\u0631-\u0688\u06cc\u0679\u0627-\u06a9\u06cc-\u062d\u0641\u0627\u0638\u062a",children:"\u0631\u0627\u0632\u062f\u0627\u0631\u06cc \u0627\u0648\u0631 \u0688\u06cc\u0679\u0627 \u06a9\u06cc \u062d\u0641\u0627\u0638\u062a"}),(0,i.jsx)(n.p,{children:"\u062c\u06cc\u0633\u06d2 \u062c\u06cc\u0633\u06d2 \u06c1\u06cc\u0648\u0645\u0646\u0648\u0627\u0626\u0688 \u0631\u0648\u0628\u0648\u0679\u0633 \u0628\u06d2 \u062a\u062d\u0627\u0634\u0627 \u0630\u0627\u062a\u06cc \u0688\u06cc\u0679\u0627 \u062c\u0645\u0639 \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba \u0627\u0648\u0631 \u067e\u0631\u0648\u0633\u06cc\u0633 \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba\u060c \u0631\u0627\u0632\u062f\u0627\u0631\u06cc \u0627\u0648\u0631 \u0688\u06cc\u0679\u0627 \u06a9\u06cc \u062d\u0641\u0627\u0638\u062a \u0627\u06cc\u06a9 \u0627\u06c1\u0645 \u0627\u062e\u0644\u0627\u0642\u06cc \u062a\u0634\u0648\u06cc\u0634 \u0628\u0646 \u062c\u0627\u062a\u06cc \u06c1\u06d2\u06d4 \u06cc\u06c1 \u0633\u0633\u0679\u0645\u0632 \u0627\u06a9\u062b\u0631 \u062d\u0633\u0627\u0633 \u0645\u0639\u0644\u0648\u0645\u0627\u062a \u062c\u0645\u0639 \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba \u0628\u0634\u0645\u0648\u0644 \u0628\u0627\u0626\u06cc\u0648 \u0645\u06cc\u0679\u0631\u06a9 \u0688\u06cc\u0679\u0627\u060c \u0637\u0631\u0632 \u0639\u0645\u0644 \u06a9\u06d2 \u067e\u06cc\u0679\u0631\u0646\u0632\u060c \u0627\u0648\u0631 \u0630\u0627\u062a\u06cc \u062a\u0631\u062c\u06cc\u062d\u0627\u062a\u06d4"}),(0,i.jsx)(n.h3,{id:"\u0688\u06cc\u0679\u0627-\u06a9\u0645\u06cc-\u0627\u0648\u0631-\u0631\u0636\u0627\u0645\u0646\u062f\u06cc",children:"\u0688\u06cc\u0679\u0627 \u06a9\u0645\u06cc \u0627\u0648\u0631 \u0631\u0636\u0627\u0645\u0646\u062f\u06cc"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# \u0645\u062b\u0627\u0644: \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u0633\u0633\u0679\u0645\u0632 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0631\u0627\u0632\u062f\u0627\u0631\u06cc \u06a9\u06cc \u062d\u0641\u0627\u0638\u062a \u06a9\u0627 \u0641\u0631\u06cc\u0645 \u0648\u0631\u06a9\nimport hashlib\nimport secrets\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional\nimport json\n\nclass DataProtectionFramework:\n    def __init__(self):\n        self.collected_data = {}\n        self.consent_records = {}\n        self.retention_policies = {}\n        self.encryption_keys = {}\n\n    def request_consent(self, user_id: str, data_types: List[str], purpose: str, duration_hours: int) -> str:\n        \"\"\"\n        \u0688\u06cc\u0679\u0627 \u062c\u0645\u0639 \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0635\u0627\u0631\u0641 \u06a9\u06cc \u0631\u0636\u0627\u0645\u0646\u062f\u06cc \u06a9\u06cc \u062f\u0631\u062e\u0648\u0627\u0633\u062a \u06a9\u0631\u06cc\u06ba\n        \u0631\u0636\u0627\u0645\u0646\u062f\u06cc \u0679\u0648\u06a9\u0646 \u0644\u0648\u0679\u0627\u0626\u06cc\u06ba\n        \"\"\"\n        consent_token = secrets.token_urlsafe(32)\n\n        consent_record = {\n            'user_id': user_id,\n            'data_types': data_types,\n            'purpose': purpose,\n            'requested_at': datetime.now().isoformat(),\n            'expires_at': (datetime.now() + timedelta(hours=duration_hours)).isoformat(),\n            'granted': False\n        }\n\n        self.consent_records[consent_token] = consent_record\n        return consent_token\n\n    def grant_consent(self, consent_token: str) -> bool:\n        \"\"\"\n        \u0688\u06cc\u0679\u0627 \u062c\u0645\u0639 \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0631\u0636\u0627\u0645\u0646\u062f\u06cc \u062f\u06cc\u06ba\n        \"\"\"\n        if consent_token in self.consent_records:\n            self.consent_records[consent_token]['granted'] = True\n            self.consent_records[consent_token]['granted_at'] = datetime.now().isoformat()\n            return True\n        return False\n\n    def collect_data(self, consent_token: str, data_type: str, data: any) -> bool:\n        \"\"\"\n        \u0627\u06af\u0631 \u0631\u0636\u0627\u0645\u0646\u062f\u06cc \u062f\u06cc \u06af\u0626\u06cc \u06c1\u0648 \u0627\u0648\u0631 \u062f\u0631\u0633\u062a \u06c1\u0648 \u062a\u0648 \u0688\u06cc\u0679\u0627 \u062c\u0645\u0639 \u06a9\u0631\u06cc\u06ba\n        \"\"\"\n        if consent_token not in self.consent_records:\n            return False\n\n        consent = self.consent_records[consent_token]\n\n        # \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba \u06a9\u06c1 \u06a9\u06cc\u0627 \u0631\u0636\u0627\u0645\u0646\u062f\u06cc \u062f\u06cc \u06af\u0626\u06cc \u06c1\u06d2 \u0627\u0648\u0631 \u062e\u062a\u0645 \u0646\u06c1\u06cc\u06ba \u06c1\u0648\u0626\u06cc\n        if not consent['granted']:\n            return False\n\n        if datetime.fromisoformat(consent['expires_at']) < datetime.now():\n            return False\n\n        # \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba \u06a9\u06c1 \u06a9\u06cc\u0627 \u062f\u0631\u062e\u0648\u0627\u0633\u062a \u06a9\u0631\u062f\u06c1 \u0688\u06cc\u0679\u0627 \u0679\u0627\u0626\u067e \u0631\u0636\u0627\u0645\u0646\u062f\u06cc \u0633\u06d2 \u0645\u0645\u0627\u062b\u0644 \u06c1\u06d2\n        if data_type not in consent['data_types']:\n            return False\n\n        # \u0627\u0646\u06a9\u0631\u067e\u0679 \u0627\u0648\u0631 \u0688\u06cc\u0679\u0627 \u0627\u0633\u0679\u0648\u0631 \u06a9\u0631\u06cc\u06ba\n        encrypted_data = self._encrypt_data(data, consent['user_id'])\n\n        if consent['user_id'] not in self.collected_data:\n            self.collected_data[consent['user_id']] = {}\n\n        if data_type not in self.collected_data[consent['user_id']]:\n            self.collected_data[consent['user_id']][data_type] = []\n\n        self.collected_data[consent['user_id']][data_type].append({\n            'timestamp': datetime.now().isoformat(),\n            'data': encrypted_data,\n            'consent_token': consent_token\n        })\n\n        return True\n\n    def _encrypt_data(self, data: any, user_id: str) -> str:\n        \"\"\"\n        \u0635\u0627\u0631\u0641 \u0645\u062e\u0635\u0648\u0635 \u06a9\u0644\u06cc\u062f \u06a9\u0627 \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631 \u06a9\u06d2 \u0688\u06cc\u0679\u0627 \u0627\u0646\u06a9\u0631\u067e\u0679 \u06a9\u0631\u06cc\u06ba\n        \"\"\"\n        if user_id not in self.encryption_keys:\n            self.encryption_keys[user_id] = secrets.token_bytes(32)\n\n        key = self.encryption_keys[user_id]\n        # \u062d\u0642\u06cc\u0642\u06cc \u0646\u0641\u0627\u0630 \u0645\u06cc\u06ba\u060c \u0645\u0646\u0627\u0633\u0628 \u0627\u0646\u06a9\u0631\u067e\u0634\u0646 \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631\u06cc\u06ba (\u0645\u062b\u0644\u0627\u064b Fernet)\n        # \u06cc\u06c1 \u0627\u06cc\u06a9 \u0633\u0627\u062f\u06c1 \u0645\u062b\u0627\u0644 \u06c1\u06d2\n        data_str = json.dumps(data, default=str)\n        encrypted = hashlib.sha256((data_str + key.hex()).encode()).hexdigest()\n        return encrypted\n\n    def anonymize_data(self, user_id: str, data_type: str) -> List[any]:\n        \"\"\"\n        \u067e\u06c1\u0686\u0627\u0646 \u0648\u0627\u0644\u06cc \u0645\u0639\u0644\u0648\u0645\u0627\u062a \u06c1\u0679\u0627 \u06a9\u0631 \u062c\u0645\u0639 \u06a9\u0631\u062f\u06c1 \u0688\u06cc\u0679\u0627 \u06a9\u0648 \u06af\u0645\u0646\u0627\u0645 \u0628\u0646\u0627\u0626\u06cc\u06ba\n        \"\"\"\n        if user_id not in self.collected_data:\n            return []\n\n        if data_type not in self.collected_data[user_id]:\n            return []\n\n        # \u062d\u0642\u06cc\u0642\u06cc \u0646\u0641\u0627\u0630 \u0645\u06cc\u06ba\u060c \u0645\u0646\u0627\u0633\u0628 \u06af\u0645\u0646\u0627\u0645 \u06a9\u0646\u06cc \u06a9\u06cc \u062a\u06a9\u0646\u06cc\u06a9\u06cc\u06ba \u0644\u0627\u06af\u0648 \u06a9\u0631\u06cc\u06ba\n        # \u06cc\u06c1 \u0627\u06cc\u06a9 \u0633\u0627\u062f\u06c1 \u0645\u062b\u0627\u0644 \u06c1\u06d2\n        anonymized_data = []\n        for record in self.collected_data[user_id][data_type]:\n            # \u067e\u06c1\u0686\u0627\u0646 \u0648\u0627\u0644\u06cc \u0645\u0639\u0644\u0648\u0645\u0627\u062a \u06c1\u0679\u0627\u0626\u06cc\u06ba \u06cc\u0627 \u06c1\u06cc\u0634 \u06a9\u0631\u06cc\u06ba\n            anonymized_data.append({\n                'timestamp': record['timestamp'],\n                'data_hash': hashlib.sha256(record['data'].encode()).hexdigest()[:16]\n            })\n\n        return anonymized_data\n\n    def set_retention_policy(self, data_type: str, days: int):\n        \"\"\"\n        \u0645\u062e\u0635\u0648\u0635 \u0688\u06cc\u0679\u0627 \u0679\u0627\u0626\u067e \u06a9\u06d2 \u0644\u06cc\u06d2 \u0688\u06cc\u0679\u0627 \u0631\u06cc\u0679\u06cc\u0646\u0634\u0646 \u067e\u0627\u0644\u06cc\u0633\u06cc \u0633\u06cc\u0679 \u06a9\u0631\u06cc\u06ba\n        \"\"\"\n        self.retention_policies[data_type] = days\n\n    def cleanup_expired_data(self):\n        \"\"\"\n        \u0631\u06cc\u0679\u06cc\u0646\u0634\u0646 \u0645\u062f\u062a \u0633\u06d2 \u062a\u062c\u0627\u0648\u0632 \u06a9\u0631 \u0686\u06a9\u06d2 \u0688\u06cc\u0679\u0627 \u06a9\u0648 \u06c1\u0679\u0627 \u062f\u06cc\u06ba\n        \"\"\"\n        current_time = datetime.now()\n\n        for user_id, user_data in self.collected_data.items():\n            for data_type, records in user_data.items():\n                if data_type in self.retention_policies:\n                    retention_days = self.retention_policies[data_type]\n                    cutoff_date = current_time - timedelta(days=retention_days)\n\n                    # \u062e\u062a\u0645 \u0634\u062f\u06c1 \u0631\u06cc\u06a9\u0627\u0631\u0688 \u0641\u0644\u0679\u0631 \u06a9\u0631\u06cc\u06ba\n                    filtered_records = [\n                        record for record in records\n                        if datetime.fromisoformat(record['timestamp']) >= cutoff_date\n                    ]\n\n                    self.collected_data[user_id][data_type] = filtered_records\n\n# \u0645\u062b\u0627\u0644 \u06a9\u0627 \u0627\u0633\u062a\u0639\u0645\u0627\u0644\ndef privacy_example():\n    privacy_framework = DataProtectionFramework()\n\n    # \u0631\u06cc\u0679\u06cc\u0646\u0634\u0646 \u067e\u0627\u0644\u06cc\u0633\u06cc\u0632 \u0633\u06cc\u0679 \u06a9\u0631\u06cc\u06ba\n    privacy_framework.set_retention_policy('face_recognition', 30)\n    privacy_framework.set_retention_policy('voice_data', 7)\n    privacy_framework.set_retention_policy('behavioral_data', 90)\n\n    # \u0686\u06c1\u0631\u06d2 \u06a9\u06cc \u0634\u0646\u0627\u062e\u062a \u06a9\u06d2 \u0644\u06cc\u06d2 \u0631\u0636\u0627\u0645\u0646\u062f\u06cc \u06a9\u06cc \u062f\u0631\u062e\u0648\u0627\u0633\u062a \u06a9\u0631\u06cc\u06ba\n    consent_token = privacy_framework.request_consent(\n        user_id='user_123',\n        data_types=['face_recognition', 'behavioral_data'],\n        purpose='personalized interaction',\n        duration_hours=24\n    )\n\n    print(f\"\u0631\u0636\u0627\u0645\u0646\u062f\u06cc \u06a9\u06cc \u062f\u0631\u062e\u0648\u0627\u0633\u062a \u06a9\u06cc \u06af\u0626\u06cc\u06d4 \u0679\u0648\u06a9\u0646: {consent_token[:8]}...\")\n\n    # \u0635\u0627\u0631\u0641 \u0631\u0636\u0627\u0645\u0646\u062f\u06cc \u062f\u06cc\u062a\u0627 \u06c1\u06d2\n    privacy_framework.grant_consent(consent_token)\n\n    # \u0686\u06c1\u0631\u06d2 \u06a9\u0627 \u0688\u06cc\u0679\u0627 \u062c\u0645\u0639 \u06a9\u0631\u06cc\u06ba\n    face_data = {\n        'landmarks': [[x, y] for x in range(10) for y in range(10)],\n        'confidence': 0.95\n    }\n\n    success = privacy_framework.collect_data(consent_token, 'face_recognition', face_data)\n    print(f\"\u0686\u06c1\u0631\u06d2 \u06a9\u0627 \u0688\u06cc\u0679\u0627 \u062c\u0645\u0639 \u06a9\u0631\u0646\u0627 \u06a9\u0627\u0645\u06cc\u0627\u0628: {success}\")\n\n    # \u062a\u062c\u0632\u06cc\u06c1 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0688\u06cc\u0679\u0627 \u06af\u0645\u0646\u0627\u0645 \u06a9\u0631\u06cc\u06ba\n    anonymized = privacy_framework.anonymize_data('user_123', 'face_recognition')\n    print(f\"\u06af\u0645\u0646\u0627\u0645 \u0631\u06cc\u06a9\u0627\u0631\u0688: {len(anonymized)}\")\n\n    return privacy_framework\n"})}),(0,i.jsx)(n.h2,{id:"\u0627\u0646\u0633\u0627\u0646-\u0631\u0648\u0628\u0648\u0679-\u0628\u0627\u062a-\u0686\u06cc\u062a-\u06a9\u06cc-\u0633\u06cc\u0641\u0679\u06cc",children:"\u0627\u0646\u0633\u0627\u0646-\u0631\u0648\u0628\u0648\u0679 \u0628\u0627\u062a \u0686\u06cc\u062a \u06a9\u06cc \u0633\u06cc\u0641\u0679\u06cc"}),(0,i.jsx)(n.p,{children:"\u0645\u062d\u0641\u0648\u0638 \u0627\u0646\u0633\u0627\u0646-\u0631\u0648\u0628\u0648\u0679 \u0628\u0627\u062a \u0686\u06cc\u062a \u06a9\u0648 \u062c\u0633\u0645\u0627\u0646\u06cc\u060c \u0646\u0641\u0633\u06cc\u0627\u062a\u06cc\u060c \u0627\u0648\u0631 \u0645\u0639\u0627\u0634\u0631\u062a\u06cc \u0639\u0648\u0627\u0645\u0644 \u06a9\u06d2 \u0628\u0627\u0631\u06d2 \u0645\u06cc\u06ba \u0627\u062d\u062a\u06cc\u0627\u0637 \u0633\u06d2 \u063a\u0648\u0631 \u06a9\u0631\u0646\u06d2 \u06a9\u06cc \u0636\u0631\u0648\u0631\u062a \u06c1\u0648\u062a\u06cc \u06c1\u06d2\u06d4 \u062c\u06cc\u0633\u06d2 \u062c\u06cc\u0633\u06d2 \u06c1\u06cc\u0648\u0645\u0646\u0648\u0627\u0626\u0688 \u0631\u0648\u0628\u0648\u0679\u0633 \u0627\u0646\u0633\u0627\u0646\u06cc \u0645\u0627\u062d\u0648\u0644 \u0645\u06cc\u06ba \u0639\u0627\u0645 \u06c1\u0648\u062a\u06d2 \u062c\u0627\u062a\u06d2 \u06c1\u06cc\u06ba\u060c \u0645\u062d\u0641\u0648\u0638 \u0627\u0648\u0631 \u0645\u0646\u0627\u0633\u0628 \u0628\u0627\u062a \u0686\u06cc\u062a \u06a9\u0648 \u06cc\u0642\u06cc\u0646\u06cc \u0628\u0646\u0627\u0646\u0627 \u0627\u0646\u062a\u06c1\u0627\u0626\u06cc \u0627\u06c1\u0645 \u06c1\u0648 \u062c\u0627\u062a\u0627 \u06c1\u06d2\u06d4"}),(0,i.jsx)(n.h3,{id:"\u0627\u06cc\u0686-\u0622\u0631-\u0622\u0626\u06cc-\u0645\u06cc\u06ba-\u062c\u0633\u0645\u0627\u0646\u06cc-\u0633\u06cc\u0641\u0679\u06cc",children:"\u0627\u06cc\u0686 \u0622\u0631 \u0622\u0626\u06cc \u0645\u06cc\u06ba \u062c\u0633\u0645\u0627\u0646\u06cc \u0633\u06cc\u0641\u0679\u06cc"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# \u0645\u062b\u0627\u0644: \u0627\u0646\u0633\u0627\u0646-\u0631\u0648\u0628\u0648\u0679 \u0628\u0627\u062a \u0686\u06cc\u062a \u06a9\u0627 \u0633\u06cc\u0641\u0679\u06cc \u0645\u06cc\u0646\u06cc\u062c\u0631\nimport math\nimport numpy as np\nfrom typing import Tuple, List, Optional\n\nclass HRI_SafetyManager:\n    def __init__(self):\n        self.human_proximity_threshold = 0.5  # \u0645\u06cc\u0679\u0631\n        self.collision_prediction_horizon = 1.0  # \u0633\u06cc\u06a9\u0646\u0688\n        self.safety_zones = []\n        self.human_tracking = {}\n\n    def calculate_collision_risk(self, robot_pos: Tuple[float, float, float],\n                                robot_vel: Tuple[float, float, float],\n                                human_pos: Tuple[float, float, float],\n                                human_vel: Tuple[float, float, float]) -> float:\n        \"\"\"\n        \u0631\u0648\u0628\u0648\u0679 \u0627\u0648\u0631 \u0627\u0646\u0633\u0627\u0646 \u06a9\u06d2 \u062f\u0631\u0645\u06cc\u0627\u0646 \u0679\u06a9\u0631\u0627\u0624 \u06a9\u0627 \u062e\u0637\u0631\u06c1 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba\n        0 \u0627\u0648\u0631 1 \u06a9\u06d2 \u062f\u0631\u0645\u06cc\u0627\u0646 \u062e\u0637\u0631\u06c1 \u0648\u06cc\u0644\u06cc\u0648 \u0644\u0648\u0679\u0627\u0626\u06cc\u06ba\n        \"\"\"\n        # \u0631\u06cc\u0644\u06cc\u0679\u06cc\u0648 \u067e\u0648\u0632\u06cc\u0634\u0646 \u0627\u0648\u0631 \u0648\u06cc\u0644\u0648\u0633\u06cc\u0679\u06cc \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba\n        rel_pos = np.array(robot_pos) - np.array(human_pos)\n        rel_vel = np.array(robot_vel) - np.array(human_vel)\n\n        # \u0631\u0648\u0628\u0648\u0679 \u0627\u0648\u0631 \u0627\u0646\u0633\u0627\u0646 \u06a9\u06d2 \u062f\u0631\u0645\u06cc\u0627\u0646 \u0641\u0627\u0635\u0644\u06c1\n        distance = np.linalg.norm(rel_pos)\n\n        # \u0645\u0633\u062a\u0642\u0628\u0644 \u06a9\u06cc \u067e\u0648\u0632\u06cc\u0634\u0646\u0632 \u06a9\u06cc \u067e\u06cc\u0634\u0646 \u06af\u0648\u0626\u06cc \u06a9\u0631\u06cc\u06ba\n        future_robot_pos = np.array(robot_pos) + np.array(robot_vel) * self.collision_prediction_horizon\n        future_human_pos = np.array(human_pos) + np.array(human_vel) * self.collision_prediction_horizon\n\n        future_distance = np.linalg.norm(future_robot_pos - future_human_pos)\n\n        # \u0645\u0648\u062c\u0648\u062f\u06c1 \u0627\u0648\u0631 \u0645\u062a\u0648\u0642\u0639 \u0641\u0627\u0635\u0644\u0648\u06ba \u06a9\u06cc \u0628\u0646\u06cc\u0627\u062f \u067e\u0631 \u062e\u0637\u0631\u06c1 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba\n        current_risk = max(0, 1 - distance / self.human_proximity_threshold)\n        future_risk = max(0, 1 - future_distance / self.human_proximity_threshold)\n\n        # \u0645\u0633\u062a\u0642\u0628\u0644 \u06a9\u06d2 \u062e\u0637\u0631\u06d2 \u06a9\u0648 \u0632\u06cc\u0627\u062f\u06c1 \u0648\u0632\u0646 \u062f\u06cc\u06ba \u06a9\u06cc\u0648\u0646\u06a9\u06c1 \u06cc\u06c1 \u0645\u062a\u0648\u0642\u0639 \u0679\u06a9\u0631\u0627\u0624 \u06a9\u06cc \u0646\u0645\u0627\u0626\u0646\u062f\u06af\u06cc \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n        risk = 0.3 * current_risk + 0.7 * future_risk\n\n        return min(risk, 1.0)\n\n    def enforce_safety_zone(self, robot_pos: Tuple[float, float, float],\n                           human_pos: Tuple[float, float, float]) -> Tuple[float, float, float]:\n        \"\"\"\n        \u0627\u0646\u0633\u0627\u0646 \u0633\u06d2 \u06a9\u0645 \u0627\u0632 \u06a9\u0645 \u0641\u0627\u0635\u0644\u06c1 \u0628\u0631\u0642\u0631\u0627\u0631 \u0631\u06a9\u06be\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0645\u062d\u0641\u0648\u0638 \u062d\u0631\u06a9\u062a \u0648\u06cc\u06a9\u0679\u0631 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba\n        \"\"\"\n        rel_vector = np.array(robot_pos) - np.array(human_pos)\n        distance = np.linalg.norm(rel_vector)\n\n        if distance < self.human_proximity_threshold:\n            # \u0631\u06cc\u067e\u0644\u0633\u0648\u06cc\u0641 \u0641\u0648\u0631\u0633 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba\n            if distance < 0.1:  # \u0628\u06c1\u062a \u0642\u0631\u06cc\u0628\u060c \u0645\u0636\u0628\u0648\u0637 \u0631\u06cc\u067e\u0644\u0633\u0648\u06cc\u0641\n                force_magnitude = 2.0\n            else:\n                # \u0645\u0639\u06a9\u0648\u0633 \u0631\u0634\u062a\u06c1: \u0642\u0631\u06cc\u0628 = \u0645\u0636\u0628\u0648\u0637 \u0631\u06cc\u067e\u0644\u0633\u0648\u06cc\u0641\n                force_magnitude = 0.5 / distance\n\n            # \u0627\u0646\u0633\u0627\u0646 \u0633\u06d2 \u062f\u0648\u0631 \u06c1\u0648\u0646\u06d2 \u06a9\u06cc \u0633\u0645\u062a \u06a9\u0648 \u0646\u0627\u0631\u0645\u0644\u0627\u0626\u0632 \u06a9\u0631\u06cc\u06ba\n            if distance > 0:\n                repulsion_vector = (rel_vector / distance) * force_magnitude\n            else:\n                # \u0627\u06af\u0631 \u0628\u0627\u0644\u06a9\u0644 \u0627\u0646\u0633\u0627\u0646 \u06a9\u06cc \u067e\u0648\u0632\u06cc\u0634\u0646 \u067e\u0631\u060c \u0628\u06d2 \u062a\u0631\u062a\u06cc\u0628 \u0633\u0645\u062a \u0645\u06cc\u06ba \u062d\u0631\u06a9\u062a \u06a9\u0631\u06cc\u06ba\n                repulsion_vector = np.array([np.random.uniform(-1, 1) for _ in range(3)])\n                repulsion_vector = repulsion_vector / np.linalg.norm(repulsion_vector) * force_magnitude\n\n            return tuple(repulsion_vector)\n        else:\n            # \u06a9\u0648\u0626\u06cc \u0633\u06cc\u0641\u0679\u06cc \u0645\u062f\u0627\u062e\u0644\u062a \u06a9\u06cc \u0636\u0631\u0648\u0631\u062a \u0646\u06c1\u06cc\u06ba\n            return (0.0, 0.0, 0.0)\n\n    def assess_interaction_safety(self, robot_state: Dict, human_states: List[Dict]) -> Dict:\n        \"\"\"\n        \u0627\u0646\u0633\u0627\u0646-\u0631\u0648\u0628\u0648\u0679 \u0628\u0627\u062a \u0686\u06cc\u062a \u06a9\u06cc \u0645\u062c\u0645\u0648\u0639\u06cc \u0633\u06cc\u0641\u0679\u06cc \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1 \u0644\u06cc\u06ba\n        \"\"\"\n        safety_assessment = {\n            'collision_risk': 0.0,\n            'safety_zone_violations': 0,\n            'recommended_actions': [],\n            'overall_safety_score': 1.0\n        }\n\n        for human_state in human_states:\n            # \u0679\u06a9\u0631\u0627\u0624 \u06a9\u0627 \u062e\u0637\u0631\u06c1 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba\n            risk = self.calculate_collision_risk(\n                robot_state['position'],\n                robot_state['velocity'],\n                human_state['position'],\n                human_state['velocity']\n            )\n\n            safety_assessment['collision_risk'] = max(safety_assessment['collision_risk'], risk)\n\n            # \u0633\u06cc\u0641\u0679\u06cc \u0632\u0648\u0646 \u06a9\u06cc \u062e\u0644\u0627\u0641 \u0648\u0631\u0632\u06cc \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba\n            robot_pos = np.array(robot_state['position'])\n            human_pos = np.array(human_state['position'])\n            distance = np.linalg.norm(robot_pos - human_pos)\n\n            if distance < self.human_proximity_threshold:\n                safety_assessment['safety_zone_violations'] += 1\n                safety_assessment['recommended_actions'].append(\n                    f\"\u0627\u0646\u0633\u0627\u0646 \u0633\u06d2 \u0641\u0627\u0635\u0644\u06c1 \u0628\u0631\u0642\u0631\u0627\u0631 \u0631\u06a9\u06be\u06cc\u06ba {human_state['position']} \u067e\u0631\"\n                )\n\n        # \u0645\u062c\u0645\u0648\u0639\u06cc \u0633\u06cc\u0641\u0679\u06cc \u0627\u0633\u06a9\u0648\u0631 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba (\u062e\u0637\u0631\u06d2 \u06a9\u06d2 \u0627\u0644\u0679)\n        safety_assessment['overall_safety_score'] = 1.0 - safety_assessment['collision_risk']\n\n        return safety_assessment\n\n# \u0645\u062b\u0627\u0644 \u06a9\u0627 \u0627\u0633\u062a\u0639\u0645\u0627\u0644\ndef hri_safety_example():\n    safety_manager = HRI_SafetyManager()\n\n    # \u0631\u0648\u0628\u0648\u0679 \u0627\u0633\u0679\u06cc\u0679\n    robot_state = {\n        'position': (1.0, 0.5, 0.8),\n        'velocity': (0.1, 0.0, 0.0)\n    }\n\n    # \u0627\u0646\u0633\u0627\u0646 \u0627\u0633\u0679\u06cc\u0679\u0633 (\u0645\u0627\u062d\u0648\u0644 \u0645\u06cc\u06ba \u0645\u062a\u0639\u062f\u062f \u0627\u0646\u0633\u0627\u0646)\n    human_states = [\n        {\n            'position': (0.8, 0.5, 0.8),\n            'velocity': (0.0, 0.0, 0.0)\n        },\n        {\n            'position': (2.0, 1.0, 0.8),\n            'velocity': (0.05, 0.0, 0.0)\n        }\n    ]\n\n    # \u0628\u0627\u062a \u0686\u06cc\u062a \u06a9\u06cc \u0633\u06cc\u0641\u0679\u06cc \u06a9\u0627 \u062c\u0627\u0626\u0632\u06c1 \u0644\u06cc\u06ba\n    assessment = safety_manager.assess_interaction_safety(robot_state, human_states)\n\n    print(f\"\u0679\u06a9\u0631\u0627\u0624 \u06a9\u0627 \u062e\u0637\u0631\u06c1: {assessment['collision_risk']:.2f}\")\n    print(f\"\u0633\u06cc\u0641\u0679\u06cc \u0632\u0648\u0646 \u06a9\u06cc \u062e\u0644\u0627\u0641 \u0648\u0631\u0632\u06cc\u0627\u06ba: {assessment['safety_zone_violations']}\")\n    print(f\"\u0645\u062c\u0645\u0648\u0639\u06cc \u0633\u06cc\u0641\u0679\u06cc \u0627\u0633\u06a9\u0648\u0631: {assessment['overall_safety_score']:.2f}\")\n    print(f\"\u0633\u0641\u0627\u0631\u0634 \u06a9\u0631\u062f\u06c1 \u0627\u06cc\u06a9\u0634\u0646\u0632: {assessment['recommended_actions']}\")\n\n    # \u0633\u06cc\u0641\u0679\u06cc \u0632\u0648\u0646 \u06a9\u06d2 \u0646\u0641\u0627\u0630 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba\n    repulsion_force = safety_manager.enforce_safety_zone(\n        robot_state['position'],\n        human_states[0]['position']  # \u0642\u0631\u06cc\u0628\u06cc \u0627\u0646\u0633\u0627\u0646 \u06a9\u06d2 \u062e\u0644\u0627\u0641 \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba\n    )\n\n    print(f\"\u0631\u06cc\u067e\u0644\u0633\u0648\u06cc\u0641 \u0641\u0648\u0631\u0633 \u0648\u06cc\u06a9\u0679\u0631: {repulsion_force}\")\n\n    return safety_manager\n"})}),(0,i.jsx)(n.h2,{id:"\u0627\u062e\u0644\u0627\u0642\u06cc-ai-\u062a\u0631\u0642\u06cc-\u06a9\u06cc-\u0645\u0634\u0642\u06cc\u06ba",children:"\u0627\u062e\u0644\u0627\u0642\u06cc AI \u062a\u0631\u0642\u06cc \u06a9\u06cc \u0645\u0634\u0642\u06cc\u06ba"}),(0,i.jsx)(n.p,{children:"\u0627\u062e\u0644\u0627\u0642\u06cc AI \u0633\u0633\u0679\u0645\u0632 \u06a9\u06cc \u062a\u0631\u0642\u06cc \u06a9\u0648 \u0627\u0635\u0648\u0644\u0648\u06ba \u06a9\u06cc \u067e\u0627\u0628\u0646\u062f\u06cc \u06a9\u06cc \u0636\u0631\u0648\u0631\u062a \u06c1\u0648\u062a\u06cc \u06c1\u06d2 \u062c\u0648 \u0627\u0646\u0635\u0627\u0641\u060c \u0634\u0641\u0627\u0641\u06cc\u062a\u060c \u0630\u0645\u06c1 \u062f\u0627\u0631\u06cc\u060c \u0627\u0648\u0631 \u0627\u0646\u0633\u0627\u0646\u06cc \u062d\u0642\u0648\u0642 \u06a9\u06d2 \u0627\u062d\u062a\u0631\u0627\u0645 \u06a9\u0648 \u06cc\u0642\u06cc\u0646\u06cc \u0628\u0646\u0627\u062a\u06d2 \u06c1\u06cc\u06ba\u06d4 \u0627\u0646 \u0627\u0635\u0648\u0644\u0648\u06ba \u06a9\u0648 \u062a\u0631\u0642\u06cc \u06a9\u06d2 \u0633\u0627\u0626\u06cc\u06a9\u0644 \u06a9\u06d2 \u062f\u0648\u0631\u0627\u0646 \u0634\u0627\u0645\u0644 \u06a9\u06cc\u0627 \u062c\u0627\u0646\u0627 \u0686\u0627\u06c1\u06cc\u06d2\u06d4"}),(0,i.jsx)(n.h3,{id:"\u0627\u0646\u0635\u0627\u0641-\u0627\u0648\u0631-\u062a\u0648\u0627\u0632\u0646-\u06a9\u0645\u06cc",children:"\u0627\u0646\u0635\u0627\u0641 \u0627\u0648\u0631 \u062a\u0648\u0627\u0632\u0646 \u06a9\u0645\u06cc"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# \u0645\u062b\u0627\u0644: \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 AI \u0633\u0633\u0679\u0645\u0632 \u0645\u06cc\u06ba \u0627\u0646\u0635\u0627\u0641 \u0627\u0648\u0631 \u062a\u0648\u0627\u0632\u0646 \u06a9\u0627 \u067e\u062a\u06c1 \u0644\u06af\u0627\u0646\u0627\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict, List, Any\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\nclass FairnessChecker:\n    def __init__(self):\n        self.protected_attributes = []\n        self.bias_metrics = {}\n        self.fairness_threshold = 0.1  # \u0632\u06cc\u0627\u062f\u06c1 \u0633\u06d2 \u0632\u06cc\u0627\u062f\u06c1 \u0642\u0627\u0628\u0644 \u0642\u0628\u0648\u0644 \u062a\u0648\u0627\u0632\u0646 \u0641\u0631\u0642\n\n    def add_protected_attribute(self, attribute: str):\n        \"\"\"\u062a\u0648\u0627\u0632\u0646 \u0686\u06cc\u06a9 \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0627\u06cc\u06a9 \u0645\u062d\u0641\u0648\u0638 \u0627\u0679\u0631\u06cc\u0628\u06cc\u0648\u0679 \u0634\u0627\u0645\u0644 \u06a9\u0631\u06cc\u06ba\"\"\"\n        if attribute not in self.protected_attributes:\n            self.protected_attributes.append(attribute)\n\n    def calculate_disparate_impact(self, predictions: List[int],\n                                  actual: List[int],\n                                  protected_group: List[bool],\n                                  favorable_outcome: int = 1) -> float:\n        \"\"\"\n        \u0645\u062e\u062a\u0644\u0641 \u0627\u062b\u0631 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba\n        \u0645\u062d\u0641\u0648\u0638 \u0627\u0648\u0631 \u063a\u06cc\u0631 \u0645\u062d\u0641\u0648\u0638 \u06af\u0631\u0648\u067e\u0633 \u06a9\u06d2 \u062f\u0631\u0645\u06cc\u0627\u0646 \u0645\u0637\u0644\u0648\u0628\u06c1 \u0646\u062a\u0627\u0626\u062c \u06a9\u06d2 \u062a\u0646\u0627\u0633\u0628 \u06a9\u0648 \u0644\u0648\u0679\u0627\u0626\u06cc\u06ba\n        \"\"\"\n        protected_favorable = sum(1 for i, pred in enumerate(predictions)\n                                 if protected_group[i] and pred == favorable_outcome)\n        protected_total = sum(1 for p in protected_group if p)\n\n        unprotected_favorable = sum(1 for i, pred in enumerate(predictions)\n                                   if not protected_group[i] and pred == favorable_outcome)\n        unprotected_total = sum(1 for p in protected_group if not p)\n\n        if unprotected_total == 0 or protected_total == 0:\n            return 1.0  # \u0627\u06af\u0631 \u0627\u06cc\u06a9 \u06af\u0631\u0648\u067e \u06a9\u06d2 \u06a9\u0648\u0626\u06cc \u0645\u0645\u0628\u0631 \u0646\u06c1 \u06c1\u0648\u06ba \u062a\u0648 \u0646\u06c1\u06cc\u06ba \u06af\u0646\u0627 \u062c\u0627 \u0633\u06a9\u062a\u0627\n\n        protected_rate = protected_favorable / protected_total\n        unprotected_rate = unprotected_favorable / unprotected_total\n\n        if unprotected_rate == 0:\n            return float('inf') if protected_rate > 0 else 1.0\n\n        return protected_rate / unprotected_rate\n\n    def detect_bias_in_robot_behavior(self, robot_decisions: List[Dict]) -> Dict:\n        \"\"\"\n        \u0631\u0648\u0628\u0648\u0679 \u0641\u06cc\u0635\u0644\u06c1 \u0633\u0627\u0632\u06cc \u0645\u06cc\u06ba \u0645\u0645\u06a9\u0646\u06c1 \u062a\u0648\u0627\u0632\u0646 \u06a9\u0627 \u067e\u062a\u06c1 \u0644\u06af\u0627\u0626\u06cc\u06ba\n        \"\"\"\n        bias_report = {}\n\n        for attr in self.protected_attributes:\n            # \u0641\u06cc\u0635\u0644\u06d2 \u06a9\u0648 \u0645\u062d\u0641\u0648\u0638 \u0627\u0679\u0631\u06cc\u0628\u06cc\u0648\u0679 \u06a9\u06d2 \u0644\u062d\u0627\u0638 \u0633\u06d2 \u06af\u0631\u0648\u067e \u06a9\u0631\u06cc\u06ba\n            groups = {}\n            for decision in robot_decisions:\n                attr_value = decision.get(attr, 'unknown')\n                if attr_value not in groups:\n                    groups[attr_value] = []\n                groups[attr_value].append(decision)\n\n            # \u06c1\u0631 \u06af\u0631\u0648\u067e \u06a9\u06d2 \u0644\u06cc\u06d2 \u06a9\u0627\u0631\u06a9\u0631\u062f\u06af\u06cc \u06a9\u06d2 \u0645\u06cc\u0679\u0631\u06a9\u0633 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba\n            group_metrics = {}\n            for group_value, group_decisions in groups.items():\n                if len(group_decisions) == 0:\n                    continue\n\n                predictions = [d.get('prediction', 0) for d in group_decisions]\n                actual = [d.get('actual', 0) for d in group_decisions]\n\n                if len(set(actual)) > 1:  # \u0645\u062b\u0628\u062a \u0627\u0648\u0631 \u0645\u0646\u0641\u06cc \u06a9\u06cc\u0633\u0632 \u062f\u0648\u0646\u0648\u06ba \u06a9\u06cc \u0636\u0631\u0648\u0631\u062a \u06c1\u06d2\n                    group_metrics[group_value] = {\n                        'accuracy': accuracy_score(actual, predictions),\n                        'precision': precision_score(actual, predictions, zero_division=0),\n                        'recall': recall_score(actual, predictions, zero_division=0),\n                        'count': len(group_decisions)\n                    }\n\n            # \u06af\u0631\u0648\u067e\u0633 \u06a9\u06d2 \u062f\u0631\u0645\u06cc\u0627\u0646 \u062a\u0648\u0627\u0632\u0646 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0686\u06cc\u06a9 \u06a9\u0631\u06cc\u06ba\n            if len(group_metrics) > 1:\n                metric_values = {metric: [g[metric] for g in group_metrics.values()]\n                               for metric in ['accuracy', 'precision', 'recall']}\n\n                bias_detected = False\n                for metric, values in metric_values.items():\n                    if len(values) > 1:\n                        max_diff = max(values) - min(values)\n                        if max_diff > self.fairness_threshold:\n                            bias_detected = True\n\n                bias_report[attr] = {\n                    'metrics': group_metrics,\n                    'bias_detected': bias_detected,\n                    'max_difference': max([max(v) - min(v) for v in metric_values.values()]) if metric_values else 0\n                }\n\n        return bias_report\n\n    def recommend_bias_mitigation(self, bias_report: Dict) -> List[str]:\n        \"\"\"\n        \u062a\u0648\u0627\u0632\u0646 \u06a9\u0645\u06cc \u06a9\u06cc \u062d\u06a9\u0645\u062a \u0639\u0645\u0644\u06cc\u0648\u06ba \u06a9\u06cc \u0633\u0641\u0627\u0631\u0634 \u06a9\u0631\u06cc\u06ba\n        \"\"\"\n        recommendations = []\n\n        for attr, report in bias_report.items():\n            if report['bias_detected']:\n                recommendations.append(\n                    f\"{attr} \u0627\u0679\u0631\u06cc\u0628\u06cc\u0648\u0679 \u0645\u06cc\u06ba \u0646\u0645\u0627\u06cc\u0627\u06ba \u062a\u0648\u0627\u0632\u0646 \u062f\u0631\u06cc\u0627\u0641\u062a \u06c1\u0648\u0627\u06d4 \"\n                    f\"\u0632\u06cc\u0627\u062f\u06c1 \u0633\u06d2 \u0632\u06cc\u0627\u062f\u06c1 \u0641\u0631\u0642: {report['max_difference']:.3f}. \"\n                    f\"\u063a\u0648\u0631 \u06a9\u0631\u06cc\u06ba: {self._get_mitigation_strategies(attr)}\"\n                )\n\n        return recommendations\n\n    def _get_mitigation_strategies(self, attribute: str) -> str:\n        \"\"\"\n        \u0645\u062e\u0635\u0648\u0635 \u0627\u0679\u0631\u06cc\u0628\u06cc\u0648\u0679 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0645\u0646\u0627\u0633\u0628 \u06a9\u0645\u06cc \u06a9\u06cc \u062d\u06a9\u0645\u062a \u0639\u0645\u0644\u06cc\u0627\u06ba \u062d\u0627\u0635\u0644 \u06a9\u0631\u06cc\u06ba\n        \"\"\"\n        strategies = {\n            'gender': \"\u0688\u06cc\u0679\u0627 \u0628\u06cc\u0644\u0646\u0633\u0646\u06af\u060c \u0645\u062e\u0627\u0644\u0641 \u0688\u06cc \u0628\u0627\u0626\u0633\u060c \u0627\u0646\u0635\u0627\u0641 \u06a9\u06cc \u067e\u0627\u0628\u0646\u062f\u06cc\u0627\u06ba\",\n            'age': \"\u0633\u0679\u0631\u06cc\u0679\u06cc\u0641\u0627\u0626\u0688 \u0633\u06cc\u0645\u067e\u0644\u0646\u06af\u060c \u0639\u0645\u0631 \u06a9\u0627 \u062e\u06cc\u0627\u0644 \u0631\u06a9\u06be\u0646\u06d2 \u0648\u0627\u0644\u0627 \u062a\u0631\u0628\u06cc\u062a\u060c \u0628\u0627\u0642\u0627\u0639\u062f\u06c1 \u062a\u0648\u0627\u0632\u0646 \u0622\u0688\u0679\u0633\",\n            'race': \"\u0645\u062a\u0646\u0648\u0639 \u062a\u0631\u0628\u06cc\u062a \u0688\u06cc\u0679\u0627\u060c \u062a\u0648\u0627\u0632\u0646 \u06a9\u0627 \u067e\u062a\u06c1 \u0644\u06af\u0627\u0646\u06d2 \u0648\u0627\u0644\u0627 \u0679\u0648\u0644\u060c \u062c\u0627\u0645\u0639 \u0688\u06cc\u0632\u0627\u0626\u0646\",\n            'disability': \"Accessibility features, universal design, bias testing\"\n        }\n        return strategies.get(attribute, \"\u0688\u06cc\u0679\u0627 \u0622\u0688\u0679\u0646\u06af\u060c \u062a\u0648\u0627\u0632\u0646 \u06a9\u0627 \u067e\u062a\u06c1 \u0644\u06af\u0627\u0646\u0627\u060c \u0627\u0646\u0635\u0627\u0641 \u06a9\u06cc \u067e\u0627\u0628\u0646\u062f\u06cc\u0627\u06ba\")\n\n# \u0645\u062b\u0627\u0644 \u06a9\u0627 \u0627\u0633\u062a\u0639\u0645\u0627\u0644\ndef fairness_example():\n    fairness_checker = FairnessChecker()\n    fairness_checker.add_protected_attribute('gender')\n    fairness_checker.add_protected_attribute('age_group')\n\n    # \u0634\u0628\u06cc\u06c1\u06cc \u0631\u0648\u0628\u0648\u0679 \u0641\u06cc\u0635\u0644\u06d2\n    robot_decisions = [\n        {'gender': 'male', 'age_group': 'adult', 'prediction': 1, 'actual': 1},\n        {'gender': 'female', 'age_group': 'adult', 'prediction': 0, 'actual': 1},\n        {'gender': 'male', 'age_group': 'elderly', 'prediction': 1, 'actual': 1},\n        {'gender': 'female', 'age_group': 'adult', 'prediction': 1, 'actual': 0},\n        {'gender': 'male', 'age_group': 'adult', 'prediction': 1, 'actual': 1},\n        {'gender': 'female', 'age_group': 'elderly', 'prediction': 0, 'actual': 0},\n    ]\n\n    # \u062a\u0648\u0627\u0632\u0646 \u06a9\u0627 \u067e\u062a\u06c1 \u0644\u06af\u0627\u0626\u06cc\u06ba\n    bias_report = fairness_checker.detect_bias_in_robot_behavior(robot_decisions)\n\n    print(\"\u062a\u0648\u0627\u0632\u0646 \u0631\u067e\u0648\u0631\u0679:\")\n    for attr, report in bias_report.items():\n        print(f\"  {attr}: \u062a\u0648\u0627\u0632\u0646 \u062f\u0631\u06cc\u0627\u0641\u062a \u06c1\u0648\u0627 = {report['bias_detected']}\")\n        print(f\"  \u0632\u06cc\u0627\u062f\u06c1 \u0633\u06d2 \u0632\u06cc\u0627\u062f\u06c1 \u0641\u0631\u0642: {report['max_difference']:.3f}\")\n\n    # \u0633\u0641\u0627\u0631\u0634\u0627\u062a \u062d\u0627\u0635\u0644 \u06a9\u0631\u06cc\u06ba\n    recommendations = fairness_checker.recommend_bias_mitigation(bias_report)\n    print(\"\\n\u0633\u0641\u0627\u0631\u0634\u0627\u062a:\")\n    for rec in recommendations:\n        print(f\"  - {rec}\")\n\n    return fairness_checker\n"})})]}),"\n",(0,i.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Safety Standards"}),": Understanding international safety standards (ISO 13482, ISO 12100, etc.) is essential for developing compliant robotic systems."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Risk Assessment"}),": Comprehensive risk assessment frameworks help identify and mitigate potential hazards in robotic systems."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Ethical Frameworks"}),": Implementing ethical decision-making frameworks ensures robots behave in accordance with moral principles."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Privacy Protection"}),": Data minimization, consent management, and anonymization techniques are crucial for protecting user privacy."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Human-Robot Safety"}),": Physical and psychological safety considerations must be integrated into all human-robot interaction scenarios."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Fairness and Bias"}),": Regular bias detection and mitigation strategies are necessary to ensure equitable robot behavior across different user groups."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Hardware Considerations"}),": Different hardware platforms require tailored safety implementations based on their capabilities and constraints."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"practice-exercises",children:"Practice Exercises"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Safety Protocol Implementation"}),": Design and implement a safety protocol for a humanoid robot that includes emergency stop functionality, collision avoidance, and human proximity detection."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Ethical Decision Framework"}),": Create an ethical decision-making system for a service robot that must choose between competing priorities while respecting human autonomy and safety."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Privacy Protection System"}),": Implement a data collection system that includes user consent management, data anonymization, and retention policies for a home robot."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Bias Detection in Robot Behavior"}),": Develop a system to detect and measure bias in a robot's interaction patterns across different demographic groups."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"HRI Safety Simulation"}),": Create a simulation environment to test human-robot interaction safety protocols under various scenarios and conditions."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"quiz-safety--ethics-in-robotics",children:"Quiz: Safety & Ethics in Robotics"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"What is the primary purpose of ISO 13482 in robotics?\na) Industrial robot safety\nb) Personal care robot safety requirements\nc) Autonomous vehicle standards\nd) Medical device regulations"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Answer: b)"})," ISO 13482 specifically addresses safety requirements for personal care robots."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"According to Asimov's Three Laws of Robotics, what is the highest priority?\na) Self-preservation\nb) Obedience to humans\nc) Do no harm to humans\nd) Protect human property"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Answer: c)"})," The First Law states that a robot may not injure a human being or, through inaction, allow a human being to come to harm, making it the highest priority."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"What is disparate impact in the context of fair AI?\na) Different error rates across groups\nb) Ratio of favorable outcomes between protected and unprotected groups\nc) Data collection bias\nd) Algorithmic complexity differences"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Answer: b)"})," Disparate impact measures the ratio of favorable outcomes between protected and unprotected groups as a measure of fairness."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"What is the recommended approach for data minimization in robotics?\na) Collect all possible data for future use\nb) Collect only data necessary for the specified purpose\nc) Share data with all stakeholders\nd) Store data indefinitely"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Answer: b)"})," Data minimization means collecting only the data necessary for the specified purpose, respecting user privacy."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'In human-robot interaction safety, what does the term "collision prediction horizon" refer?\na) Time window for detecting obstacles\nb) Time period for predicting potential collisions\nc) Distance threshold for safety zones\nd) Duration of emergency stops'}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Answer: b)"})," The collision prediction horizon is the time period used to predict potential future collisions based on current robot and human trajectories."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'Lin, P., Abney, K., & Bekey, G. A. (2012). "Robot ethics: mapping the issues for a mechanized world". AI and Society, 27(4), 447-458. This paper provides a comprehensive overview of ethical issues in robotics.'}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'Calo, R. (2017). "Artificial intelligence policy: A primer and roadmap". University of Chicago Law Review, 85, 1-57. A comprehensive guide to AI policy and ethical considerations.'}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'Sparrow, R. (2007). "Killer robots". Journal of Applied Philosophy, 24(1), 62-77. Discussion of ethical concerns regarding autonomous weapons systems.'}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'ISO 13482:2014 - "Service robots - Safety requirements for personal care robots". International Organization for Standardization. The primary standard for personal care robot safety.'}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'Winfield, A. F., & Jirotka, M. (2018). "Ethical governance is essential to building trust in robotics and artificial intelligence systems". Philosophical Transactions of the Royal Society A, 376(2133), 20180085. On the importance of ethical governance in robotics.'}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'Jobin, A., Ienca, M., & Vayena, E. (2019). "The global landscape of AI ethics guidelines". Nature Machine Intelligence, 1(9), 389-399. A comprehensive survey of AI ethics guidelines worldwide.'}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'Anderson, M., & Anderson, S. L. (Eds.). (2011). "Machine ethics". Cambridge University Press. A foundational text on implementing ethical reasoning in machines.'}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'Roff, H. M., & Arkin, R. C. (2012). "Robots should be slaves of humans and roll over before pedestrians". IEEE Intelligent Systems, 27(4), 2-4. Discussion of ethical principles for robot behavior.'}),"\n"]}),"\n"]})]})}function _(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(f,{...e})}):f(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>r});var i=t(6540);const s={},a=i.createContext(s);function o(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(a.Provider,{value:n},e.children)}},8931:(e,n,t)=>{t.d(n,{B:()=>o,n:()=>a});var i=t(6540),s=t(4848);const a=({children:e,...n})=>{const[t,a]=(0,i.useState)(!1);return(0,s.jsxs)("button",{onClick:()=>{a(!t),n.onClick&&n.onClick()},style:{backgroundColor:t?"#4caf50":"#2196f3",color:"white",border:"none",padding:"8px 16px",borderRadius:"4px",cursor:"pointer",margin:"4px"},...n,children:[t?"Personalized":"Personalize",e]})},o=({children:e,...n})=>{const[t,a]=(0,i.useState)(!1);return(0,s.jsxs)("button",{onClick:()=>{a(!t),n.onClick&&n.onClick()},style:{backgroundColor:t?"#ff9800":"#9e9e9e",color:"white",border:"none",padding:"8px 16px",borderRadius:"4px",cursor:"pointer",margin:"4px"},...n,children:[t?"\u0627\u064f\u0631\u062f\u0648":"English",e]})}}}]);